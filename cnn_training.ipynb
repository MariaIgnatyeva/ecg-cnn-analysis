{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN learning for arrhythmia classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import wfdb\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import biosppy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import save_model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import History\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, ELU, Dropout, Dense, Flatten\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all records names from [MIT-BIH Arrhythmia Database](https://physionet.org/content/mitdb/1.0.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100', '101', '102', '103', '104', '105', '106', '107', '108', '109']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = wfdb.get_record_list('mitdb')\n",
    "records[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need images of beats to learn CNN. So create and save images and labels for each beat of all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def signal_to_image(signal, folder_name, record_ind, signal_ind):\n",
    "    fig = plt.figure(frameon=False)\n",
    "    plt.plot(signal, linewidth=3.5) \n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    filename = folder_name + '/' + str(record_ind) + '_' + str(signal_ind) + '.png'\n",
    "    \n",
    "    fig.savefig(filename)\n",
    "    im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    im_gray = cv2.resize(im_gray, (128, 128))\n",
    "    cv2.imwrite(filename, im_gray)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return im_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_to_idx = {'nor': 1, 'lbb': 2, 'rbb': 5, 'apc': 0, 'pvc': 4, 'pab': 3, 'veb': 6, 'vfw': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'apc',\n",
       " 1: 'nor',\n",
       " 2: 'lbb',\n",
       " 3: 'pab',\n",
       " 4: 'pvc',\n",
       " 5: 'rbb',\n",
       " 6: 'veb',\n",
       " 7: 'vfw'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_class = dict(zip(class_to_idx.values(), class_to_idx.keys()))\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol_to_label = {'N':'nor', 'L':'lbb', 'R':'rbb', 'A':'apc', \n",
    "                   'V':'pvc', '/':'pab', 'E':'veb', '!':'vfw'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signal_ind = 0\n",
    "for record_ind, record in enumerate(records):\n",
    "    signals = wfdb.rdsamp(record, channels=[0], pb_dir='mitdb')[0]\n",
    "    ann = wfdb.rdann(record, 'atr', pb_dir='mitdb') \n",
    "    symbols = ann.symbol\n",
    "    beats = list(ann.sample)\n",
    "\n",
    "    for i in range(len(beats)):\n",
    "        if symbols[i] in list(symbol_to_label.keys()):\n",
    "            left_ind = 0 if i == 0 else beats[i - 1] + 20\n",
    "            right_ind = len(signals) if i == len(beats) - 1 else beats[i + 1] - 20\n",
    "            signal = signals[left_ind: right_ind]\n",
    "\n",
    "            signal_to_image(signal, 'signal_images', record_ind, signal_ind)\n",
    "    \n",
    "            with open('labels.txt', 'a') as f:\n",
    "                f.write(str(record_ind) + '_' + str(signal_ind) + ' ' + str(class_to_idx[symbol_to_label[symbols[i]]]))\n",
    "                f.write('\\n')\n",
    "                \n",
    "            signal_ind += 1\n",
    "\n",
    "    print(record_ind, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get images paths and get images IDs from the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_paths = glob.glob('./signal_images/*.png')\n",
    "\n",
    "cropped_paths = {}\n",
    "beg = all_paths[0].find('\\\\') + 1\n",
    "for path in all_paths:\n",
    "    end = path.rfind('.')\n",
    "    \n",
    "    number = path[beg:end]\n",
    "    record_n = int(number[:number.find('_')])\n",
    "    sig_n = int(number[number.find('_') + 1:])\n",
    "    \n",
    "    if cropped_paths.get(record_n) is None:\n",
    "        cropped_paths[record_n] = 0\n",
    "    cropped_paths[record_n] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images labels from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107668"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_labels = {}\n",
    "with open('labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        n, l = line.split()\n",
    "        id_labels[n] = int(l)\n",
    "\n",
    "len(id_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha dataset is imbalanced, so we'll need to artificially augment smaller classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([ 2546, 75052,  8075,  7028,  7130,  7259,   106,   472],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(list(id_labels.values()), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of labels from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107668"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(list(id_labels.values()))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(np.unique(labels))\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107668 [23423 48798  7516 ... 17730 28030 15725]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(labels))\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(len(indices), indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method augments smaller classes ten times cropping and shifting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cropping_images(image):\n",
    "    #Left Top Crop\n",
    "    left_top = cv2.resize(image[:96, :96], (128, 128))\n",
    "\n",
    "    #Center Top Crop\n",
    "    center_top = cv2.resize(image[:96, 16:112], (128, 128))\n",
    "\n",
    "    #Right Top Crop\n",
    "    right_top = cv2.resize(image[:96, 32:], (128, 128))\n",
    "\n",
    "    #Left Center Crop\n",
    "    left_center = cv2.resize(image[16:112, :96], (128, 128))\n",
    "\n",
    "    #Center Center Crop\n",
    "    center_center = cv2.resize(image[16:112, 16:112], (128, 128))\n",
    "\n",
    "    #Right Center Crop    \n",
    "    right_center = cv2.resize(image[16:112, 32:], (128, 128))\n",
    "\n",
    "    #Left Bottom Crop\n",
    "    left_bottom = cv2.resize(image[32:, :96], (128, 128))\n",
    "\n",
    "    #Center Bottom Crop\n",
    "    center_bottom = cv2.resize(image[32:, 16:112], (128, 128))\n",
    "\n",
    "    #Right Bottom Crop    \n",
    "    right_bottom = cv2.resize(image[32:, 32:], (128, 128))\n",
    "\n",
    "    return np.array([left_top, center_top, right_top,\n",
    "            left_center, center_center, right_center,\n",
    "            left_bottom, center_bottom, right_bottom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use generators to train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator(ind, augment=False):\n",
    "    image = cv2.imread(all_paths[ind], cv2.IMREAD_GRAYSCALE)\n",
    "    number_path = all_paths[ind][all_paths[ind].find('\\\\') + 1 : all_paths[ind].rfind('.')]\n",
    "    label = id_labels[number_path]\n",
    "    \n",
    "    if augment and label != class_to_idx['nor']:\n",
    "        cropped_images = get_cropping_images(image)\n",
    "        images = np.vstack((np.expand_dims(image, axis=0), cropped_images)) \n",
    "        yield images, [label] * len(images)\n",
    "    else:\n",
    "        yield np.expand_dims(image, 0), [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, augment=False, debug=False):\n",
    "    global batch_i\n",
    "    \n",
    "    generators = np.array([get_generator(ind, augment) for ind in range(len(all_paths))])\n",
    "    while True:\n",
    "        batch_indices = indices[(batch_i - 1) * batch_size : batch_i * batch_size]\n",
    "        batch_i += 1\n",
    "        yield [gen.__next__() for gen in generators[batch_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size, augment=False):\n",
    "    for batch in raw_batch_generator(batch_size, augment):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(e[0])\n",
    "            batch_labels.extend(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0) if not augment else np.vstack(batch_images)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size, augment=False):      \n",
    "    for batch in images_and_labels_generator(batch_size, augment):\n",
    "        batch_images = batch[0]\n",
    "        batch_images = np.expand_dims(batch_images, -1)\n",
    "        batch_labels = keras.utils.to_categorical(batch[1], NUM_CLASSES)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 128, 128, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_i = 1\n",
    "train_iterator(32, augment=True).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for saving model after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "        self.f1s = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):     \n",
    "        model_filename = self.file_name.format(epoch % 3)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom F1 score mectric for measuring training quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    f1_val = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "            \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "STEPS_PER_EPOCH = 50\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 126, 126, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 64)      36928     \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60, 60, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 58, 58, 128)       147584    \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 58, 58, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 27, 256)       295168    \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "elu_6 (ELU)                  (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              75499520  \n",
      "_________________________________________________________________\n",
      "elu_7 (ELU)                  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 16392     \n",
      "=================================================================\n",
      "Total params: 76,671,944\n",
      "Trainable params: 76,666,056\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),strides=(1,1), input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1), kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),strides=(1, 1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), strides = (1, 1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3),strides=(1, 1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), strides=(1, 1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3, 3),strides=(1, 1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',  # gradient clipping just in case\n",
    "  metrics=[keras.metrics.categorical_accuracy, f1] \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count class weights to cope with imbalanced dataset during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401212"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_for_weights = labels\n",
    "for ind in [0, 2, 3, 4, 5, 6, 7]:\n",
    "    new_labels = np.full(sum(labels == ind) * 9, ind)\n",
    "    labels_for_weights = np.append(labels_for_weights, new_labels)\n",
    "len(labels_for_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9698154 ,  0.66822337,  0.62107121,  0.71359562,  0.7033871 ,\n",
       "        0.69088717, 47.31273585, 10.6253178 ])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(labels_for_weights), labels_for_weights)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_FNAME = 'model_v3_{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 2505s 50s/step - loss: 3.0487 - categorical_accuracy: 0.5202 - f1: 0.5125\n",
      "Model saved in model_v3_0\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 2041s 41s/step - loss: 1.9249 - categorical_accuracy: 0.6332 - f1: 0.6229\n",
      "Model saved in model_v3_1\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 2500s 50s/step - loss: 1.2353 - categorical_accuracy: 0.6995 - f1: 0.6892\n",
      "Model saved in model_v3_2\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 2375s 47s/step - loss: 0.9178 - categorical_accuracy: 0.7479 - f1: 0.7446\n",
      "Model saved in model_v3_0\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 2172s 43s/step - loss: 0.7880 - categorical_accuracy: 0.7802 - f1: 0.7732\n",
      "Model saved in model_v3_1\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 2357s 47s/step - loss: 0.8071 - categorical_accuracy: 0.7569 - f1: 0.7560\n",
      "Model saved in model_v3_2\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 2560s 51s/step - loss: 0.7458 - categorical_accuracy: 0.7949 - f1: 0.7909\n",
      "Model saved in model_v3_0\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 2284s 46s/step - loss: 0.6898 - categorical_accuracy: 0.7991 - f1: 0.7958\n",
      "Model saved in model_v3_1\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 2517s 50s/step - loss: 0.6062 - categorical_accuracy: 0.8209 - f1: 0.8173\n",
      "Model saved in model_v3_2\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 2338s 47s/step - loss: 0.5817 - categorical_accuracy: 0.8259 - f1: 0.8238\n",
      "Model saved in model_v3_0\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 2282s 46s/step - loss: 0.5255 - categorical_accuracy: 0.8509 - f1: 0.8491\n",
      "Model saved in model_v3_1\n",
      "Epoch 12/100\n",
      "10/50 [=====>........................] - ETA: 32:52 - loss: 0.5282 - categorical_accuracy: 0.8316 - f1: 0.8376"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-d4cb3aa6c45c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_i = 1\n",
    "hist = History()\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(MODEL_FNAME), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_from_n_epoch(initial_epoch, load_fname):\n",
    "    global batch_i\n",
    "    global hist\n",
    "    \n",
    "    batch_i = initial_epoch * STEPS_PER_EPOCH + 1\n",
    "    hist = History()\n",
    "    model = load_model(load_fname, custom_objects={'f1':f1})\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_iterator(BATCH_SIZE, augment=True), \n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[ModelSaveCallback(MODEL_FNAME), hist],\n",
    "        verbose=1,  \n",
    "        class_weight=class_weights,\n",
    "        initial_epoch=initial_epoch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "50/50 [==============================] - 2482s 50s/step - loss: 0.6241 - categorical_accuracy: 0.8194 - f1: 0.8225\n",
      "Model saved in model_v3_2\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 2492s 50s/step - loss: 0.4698 - categorical_accuracy: 0.8559 - f1: 0.8583\n",
      "Model saved in model_v3_0\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 2659s 53s/step - loss: 0.4530 - categorical_accuracy: 0.8655 - f1: 0.8646\n",
      "Model saved in model_v3_1\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 2387s 48s/step - loss: 0.4535 - categorical_accuracy: 0.8666 - f1: 0.8678\n",
      "Model saved in model_v3_2\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 2674s 53s/step - loss: 0.4381 - categorical_accuracy: 0.8732 - f1: 0.8715\n",
      "Model saved in model_v3_0\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 2327s 47s/step - loss: 0.4403 - categorical_accuracy: 0.8645 - f1: 0.8660\n",
      "Model saved in model_v3_1\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 2419s 48s/step - loss: 0.3783 - categorical_accuracy: 0.8785 - f1: 0.8808\n",
      "Model saved in model_v3_2\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 2896s 58s/step - loss: 0.5502 - categorical_accuracy: 0.8378 - f1: 0.8369\n",
      "Model saved in model_v3_0\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 2908s 58s/step - loss: 0.2944 - categorical_accuracy: 0.9188 - f1: 0.9180\n",
      "Model saved in model_v3_1\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 3319s 66s/step - loss: 0.3241 - categorical_accuracy: 0.9010 - f1: 0.9006\n",
      "Model saved in model_v3_2\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 3124s 62s/step - loss: 0.4386 - categorical_accuracy: 0.8797 - f1: 0.8784\n",
      "Model saved in model_v3_0\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 2792s 56s/step - loss: 0.3478 - categorical_accuracy: 0.9088 - f1: 0.9066\n",
      "Model saved in model_v3_1\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 3177s 64s/step - loss: 0.2213 - categorical_accuracy: 0.9320 - f1: 0.9341\n",
      "Model saved in model_v3_2\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 2763s 55s/step - loss: 0.3260 - categorical_accuracy: 0.9003 - f1: 0.9004\n",
      "Model saved in model_v3_0\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 2837s 57s/step - loss: 0.3083 - categorical_accuracy: 0.9052 - f1: 0.9044\n",
      "Model saved in model_v3_1\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 2483s 50s/step - loss: 0.3126 - categorical_accuracy: 0.9154 - f1: 0.9155\n",
      "Model saved in model_v3_2\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 3321s 66s/step - loss: 0.2387 - categorical_accuracy: 0.9284 - f1: 0.9273\n",
      "Model saved in model_v3_0\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 3167s 63s/step - loss: 0.2359 - categorical_accuracy: 0.9332 - f1: 0.9323\n",
      "Model saved in model_v3_1\n",
      "Epoch 30/100\n",
      " 2/50 [>.............................] - ETA: 32:21 - loss: 0.2512 - categorical_accuracy: 0.9135 - f1: 0.9059"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ac72939b767d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_from_n_epoch(11, 'model_v3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "50/50 [==============================] - 3154s 63s/step - loss: 0.2899 - categorical_accuracy: 0.9081 - f1: 0.9065\n",
      "Model saved in model_v3_2\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 3279s 66s/step - loss: 0.2752 - categorical_accuracy: 0.9281 - f1: 0.9301\n",
      "Model saved in model_v3_0\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 3090s 62s/step - loss: 0.3463 - categorical_accuracy: 0.9038 - f1: 0.9022\n",
      "Model saved in model_v3_1\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 3402s 68s/step - loss: 0.3083 - categorical_accuracy: 0.9113 - f1: 0.9131\n",
      "Model saved in model_v3_2\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 3074s 61s/step - loss: 0.3095 - categorical_accuracy: 0.9085 - f1: 0.9083\n",
      "Model saved in model_v3_0\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 3171s 63s/step - loss: 0.2443 - categorical_accuracy: 0.9258 - f1: 0.9300\n",
      "Model saved in model_v3_1\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 3238s 65s/step - loss: 0.3502 - categorical_accuracy: 0.8957 - f1: 0.8996\n",
      "Model saved in model_v3_2\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 3293s 66s/step - loss: 0.2354 - categorical_accuracy: 0.9267 - f1: 0.9270\n",
      "Model saved in model_v3_0\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 3438s 69s/step - loss: 0.2180 - categorical_accuracy: 0.9329 - f1: 0.9312\n",
      "Model saved in model_v3_1\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 3272s 65s/step - loss: 0.3235 - categorical_accuracy: 0.9034 - f1: 0.9036\n",
      "Model saved in model_v3_2\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 3277s 66s/step - loss: 0.2446 - categorical_accuracy: 0.9199 - f1: 0.9232\n",
      "Model saved in model_v3_0\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 3230s 65s/step - loss: 0.2239 - categorical_accuracy: 0.9383 - f1: 0.9383\n",
      "Model saved in model_v3_1\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 3369s 67s/step - loss: 0.2286 - categorical_accuracy: 0.9304 - f1: 0.9300\n",
      "Model saved in model_v3_2\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 3346s 67s/step - loss: 0.2715 - categorical_accuracy: 0.9177 - f1: 0.9169\n",
      "Model saved in model_v3_0\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 2871s 57s/step - loss: 0.1845 - categorical_accuracy: 0.9449 - f1: 0.9437\n",
      "Model saved in model_v3_1\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 3506s 70s/step - loss: 0.3183 - categorical_accuracy: 0.9161 - f1: 0.9163\n",
      "Model saved in model_v3_2\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 2961s 59s/step - loss: 0.2834 - categorical_accuracy: 0.9200 - f1: 0.9211\n",
      "Model saved in model_v3_0\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 3047s 61s/step - loss: 0.3140 - categorical_accuracy: 0.9045 - f1: 0.9061\n",
      "Model saved in model_v3_1\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 2814s 56s/step - loss: 0.2160 - categorical_accuracy: 0.9391 - f1: 0.9399\n",
      "Model saved in model_v3_2\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 2991s 60s/step - loss: 0.2692 - categorical_accuracy: 0.9309 - f1: 0.9302\n",
      "Model saved in model_v3_0\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 3267s 65s/step - loss: 0.2980 - categorical_accuracy: 0.9046 - f1: 0.9049\n",
      "Model saved in model_v3_1\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 3074s 61s/step - loss: 0.1867 - categorical_accuracy: 0.9447 - f1: 0.9451\n",
      "Model saved in model_v3_2\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 2813s 56s/step - loss: 0.2140 - categorical_accuracy: 0.9400 - f1: 0.9408\n",
      "Model saved in model_v3_0\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 3886s 78s/step - loss: 0.2259 - categorical_accuracy: 0.9357 - f1: 0.9369\n",
      "Model saved in model_v3_1\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 3595s 72s/step - loss: 0.3039 - categorical_accuracy: 0.9077 - f1: 0.9078\n",
      "Model saved in model_v3_2\n",
      "Epoch 55/100\n",
      "25/50 [==============>...............] - ETA: 30:31 - loss: 0.2953 - categorical_accuracy: 0.9167 - f1: 0.9147"
     ]
    }
   ],
   "source": [
    "train_from_n_epoch(29, 'model_v3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 3791s 76s/step - loss: 0.2322 - categorical_accuracy: 0.9320 - f1: 0.9318\n",
      "Model saved in model_v3_0\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 3529s 71s/step - loss: 0.2852 - categorical_accuracy: 0.9124 - f1: 0.9132\n",
      "Model saved in model_v3_1\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 3157s 63s/step - loss: 0.3131 - categorical_accuracy: 0.9097 - f1: 0.9100\n",
      "Model saved in model_v3_2\n",
      "Epoch 58/100\n",
      "26/50 [==============>...............] - ETA: 30:51 - loss: 0.2634 - categorical_accuracy: 0.9243 - f1: 0.9259"
     ]
    }
   ],
   "source": [
    "train_from_n_epoch(54, 'model_v3_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 2648s 53s/step - loss: 0.2275 - categorical_accuracy: 0.9399 - f1: 0.9391\n",
      "Model saved in model_v3_0\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 2324s 46s/step - loss: 0.2314 - categorical_accuracy: 0.9345 - f1: 0.9355\n",
      "Model saved in model_v3_1\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 2364s 47s/step - loss: 0.2116 - categorical_accuracy: 0.9346 - f1: 0.9364\n",
      "Model saved in model_v3_2\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 2640s 53s/step - loss: 0.2285 - categorical_accuracy: 0.9344 - f1: 0.9326\n",
      "Model saved in model_v3_0\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 2526s 51s/step - loss: 0.2520 - categorical_accuracy: 0.9331 - f1: 0.9335\n",
      "Model saved in model_v3_1\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 2299s 46s/step - loss: 0.1513 - categorical_accuracy: 0.9496 - f1: 0.9479\n",
      "Model saved in model_v3_2\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 2471s 49s/step - loss: 0.1795 - categorical_accuracy: 0.9416 - f1: 0.9429\n",
      "Model saved in model_v3_0\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 2584s 52s/step - loss: 0.2398 - categorical_accuracy: 0.9339 - f1: 0.9333\n",
      "Model saved in model_v3_1\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 2414s 48s/step - loss: 0.2216 - categorical_accuracy: 0.9271 - f1: 0.9281\n",
      "Model saved in model_v3_2\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 2389s 48s/step - loss: 0.2565 - categorical_accuracy: 0.9299 - f1: 0.9304\n",
      "Model saved in model_v3_0\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 2269s 45s/step - loss: 0.2201 - categorical_accuracy: 0.9380 - f1: 0.9388\n",
      "Model saved in model_v3_1\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 2782s 56s/step - loss: 0.2799 - categorical_accuracy: 0.9247 - f1: 0.9238\n",
      "Model saved in model_v3_2\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 2557s 51s/step - loss: 0.2781 - categorical_accuracy: 0.9213 - f1: 0.9232\n",
      "Model saved in model_v3_0\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 2737s 55s/step - loss: 0.1585 - categorical_accuracy: 0.9542 - f1: 0.9554\n",
      "Model saved in model_v3_1\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 2583s 52s/step - loss: 0.1893 - categorical_accuracy: 0.9441 - f1: 0.9452\n",
      "Model saved in model_v3_2\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 2917s 58s/step - loss: 0.2726 - categorical_accuracy: 0.9241 - f1: 0.9238\n",
      "Model saved in model_v3_0\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 2852s 57s/step - loss: 0.1577 - categorical_accuracy: 0.9555 - f1: 0.9557\n",
      "Model saved in model_v3_1\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 2518s 50s/step - loss: 0.1901 - categorical_accuracy: 0.9487 - f1: 0.9490\n",
      "Model saved in model_v3_2\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 2538s 51s/step - loss: 0.2334 - categorical_accuracy: 0.9399 - f1: 0.9409\n",
      "Model saved in model_v3_0\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 3058s 61s/step - loss: 0.2740 - categorical_accuracy: 0.9362 - f1: 0.9363\n",
      "Model saved in model_v3_1\n",
      "Epoch 78/100\n",
      "19/50 [==========>...................] - ETA: 31:43 - loss: 0.1334 - categorical_accuracy: 0.9610 - f1: 0.9636"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-eafa3a89f6a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m57\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_from_n_epoch(57, 'model_v3_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 3305s 66s/step - loss: 0.1079 - categorical_accuracy: 0.9687 - f1: 0.9693\n",
      "Model saved in model_v3_2\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 3022s 60s/step - loss: 0.1562 - categorical_accuracy: 0.9504 - f1: 0.9513\n",
      "Model saved in model_v3_0\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 2957s 59s/step - loss: 0.1439 - categorical_accuracy: 0.9568 - f1: 0.9573\n",
      "Model saved in model_v3_1\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 3034s 61s/step - loss: 0.1764 - categorical_accuracy: 0.9490 - f1: 0.9480\n",
      "Model saved in model_v3_2\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 3066s 61s/step - loss: 0.2322 - categorical_accuracy: 0.9392 - f1: 0.9419\n",
      "Model saved in model_v3_0\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 2717s 54s/step - loss: 0.1440 - categorical_accuracy: 0.9545 - f1: 0.9548\n",
      "Model saved in model_v3_1\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 2648s 53s/step - loss: 0.1899 - categorical_accuracy: 0.9500 - f1: 0.9516\n",
      "Model saved in model_v3_2\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 3562s 71s/step - loss: 0.1433 - categorical_accuracy: 0.9601 - f1: 0.9599\n",
      "Model saved in model_v3_0\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 3606s 72s/step - loss: 0.1412 - categorical_accuracy: 0.9551 - f1: 0.9572\n",
      "Model saved in model_v3_1\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 3528s 71s/step - loss: 0.2531 - categorical_accuracy: 0.9268 - f1: 0.9257\n",
      "Model saved in model_v3_2\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 3721s 74s/step - loss: 0.1711 - categorical_accuracy: 0.9439 - f1: 0.9458\n",
      "Model saved in model_v3_0\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 4019s 80s/step - loss: 0.1788 - categorical_accuracy: 0.9456 - f1: 0.9469\n",
      "Model saved in model_v3_1\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 3601s 72s/step - loss: 0.1558 - categorical_accuracy: 0.9502 - f1: 0.9509\n",
      "Model saved in model_v3_2\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 3836s 77s/step - loss: 0.1577 - categorical_accuracy: 0.9533 - f1: 0.9547\n",
      "Model saved in model_v3_0\n",
      "Epoch 92/100\n",
      " 6/50 [==>...........................] - ETA: 28:01 - loss: 0.5106 - categorical_accuracy: 0.8838 - f1: 0.8861"
     ]
    }
   ],
   "source": [
    "train_from_n_epoch(77, 'model_v3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 92/134\n",
      " 6/50 [==>...........................] - ETA: 39:18 - loss: 0.2468 - categorical_accuracy: 0.9079 - f1: 0.9060"
     ]
    }
   ],
   "source": [
    "# here some issue with output displaying occured\n",
    "train_from_n_epoch(91, 'model_v3_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 104/134\n",
      "50/50 [==============================] - 2897s 58s/step - loss: 0.1656 - categorical_accuracy: 0.9560 - f1: 0.9554\n",
      "Model saved in model_v3_1\n",
      "Epoch 105/134\n",
      "50/50 [==============================] - 2767s 55s/step - loss: 0.1923 - categorical_accuracy: 0.9484 - f1: 0.9499\n",
      "Model saved in model_v3_2\n",
      "Epoch 106/134\n",
      "50/50 [==============================] - 2829s 57s/step - loss: 0.1540 - categorical_accuracy: 0.9544 - f1: 0.9550\n",
      "Model saved in model_v3_0\n",
      "Epoch 107/134\n",
      "50/50 [==============================] - 2805s 56s/step - loss: 0.1689 - categorical_accuracy: 0.9543 - f1: 0.9555\n",
      "Model saved in model_v3_1\n",
      "Epoch 108/134\n",
      "50/50 [==============================] - 2522s 50s/step - loss: 0.2347 - categorical_accuracy: 0.9360 - f1: 0.9391\n",
      "Model saved in model_v3_2\n",
      "Epoch 109/134\n",
      "50/50 [==============================] - 2413s 48s/step - loss: 0.1705 - categorical_accuracy: 0.9534 - f1: 0.9534\n",
      "Model saved in model_v3_0\n",
      "Epoch 110/134\n",
      "50/50 [==============================] - 2752s 55s/step - loss: 0.1827 - categorical_accuracy: 0.9364 - f1: 0.9371\n",
      "Model saved in model_v3_1\n",
      "Epoch 111/134\n",
      "50/50 [==============================] - 2547s 51s/step - loss: 0.2008 - categorical_accuracy: 0.9431 - f1: 0.9433\n",
      "Model saved in model_v3_2\n",
      "Epoch 112/134\n",
      "50/50 [==============================] - 2535s 51s/step - loss: 0.2373 - categorical_accuracy: 0.9267 - f1: 0.9281\n",
      "Model saved in model_v3_0\n",
      "Epoch 113/134\n",
      "50/50 [==============================] - 2420s 48s/step - loss: 0.1340 - categorical_accuracy: 0.9596 - f1: 0.9600\n",
      "Model saved in model_v3_1\n",
      "Epoch 114/134\n",
      "50/50 [==============================] - 2626s 53s/step - loss: 0.1935 - categorical_accuracy: 0.9488 - f1: 0.9503\n",
      "Model saved in model_v3_2\n",
      "Epoch 115/134\n",
      "50/50 [==============================] - 2551s 51s/step - loss: 0.2328 - categorical_accuracy: 0.9309 - f1: 0.9318\n",
      "Model saved in model_v3_0\n",
      "Epoch 116/134\n",
      "50/50 [==============================] - 2423s 48s/step - loss: 0.2706 - categorical_accuracy: 0.9340 - f1: 0.9345\n",
      "Model saved in model_v3_1\n",
      "Epoch 117/134\n",
      "50/50 [==============================] - 2672s 53s/step - loss: 0.1886 - categorical_accuracy: 0.9446 - f1: 0.9460\n",
      "Model saved in model_v3_2\n",
      "Epoch 118/134\n",
      "50/50 [==============================] - 2886s 58s/step - loss: 0.1544 - categorical_accuracy: 0.9509 - f1: 0.9514\n",
      "Model saved in model_v3_0\n",
      "Epoch 119/134\n",
      "50/50 [==============================] - 2827s 57s/step - loss: 0.1881 - categorical_accuracy: 0.9420 - f1: 0.9444\n",
      "Model saved in model_v3_1\n",
      "Epoch 120/134\n",
      "50/50 [==============================] - 2785s 56s/step - loss: 0.1125 - categorical_accuracy: 0.9638 - f1: 0.9629\n",
      "Model saved in model_v3_2\n",
      "Epoch 121/134\n",
      "50/50 [==============================] - 2665s 53s/step - loss: 0.1119 - categorical_accuracy: 0.9634 - f1: 0.9655\n",
      "Model saved in model_v3_0\n",
      "Epoch 122/134\n",
      "50/50 [==============================] - 3043s 61s/step - loss: 0.2194 - categorical_accuracy: 0.9472 - f1: 0.9488\n",
      "Model saved in model_v3_1\n",
      "Epoch 123/134\n",
      "50/50 [==============================] - 3130s 63s/step - loss: 0.1013 - categorical_accuracy: 0.9688 - f1: 0.9686\n",
      "Model saved in model_v3_2\n",
      "Epoch 124/134\n",
      "50/50 [==============================] - 2722s 54s/step - loss: 0.2001 - categorical_accuracy: 0.9464 - f1: 0.9478\n",
      "Model saved in model_v3_0\n",
      "Epoch 125/134\n",
      "50/50 [==============================] - 3010s 60s/step - loss: 0.1773 - categorical_accuracy: 0.9408 - f1: 0.9425\n",
      "Model saved in model_v3_1\n",
      "Epoch 126/134\n",
      "50/50 [==============================] - 3343s 67s/step - loss: 0.1675 - categorical_accuracy: 0.9518 - f1: 0.9539\n",
      "Model saved in model_v3_2\n",
      "Epoch 127/134\n",
      "50/50 [==============================] - 2797s 56s/step - loss: 0.1355 - categorical_accuracy: 0.9630 - f1: 0.9629\n",
      "Model saved in model_v3_0\n",
      "Epoch 128/134\n",
      "50/50 [==============================] - 2913s 58s/step - loss: 0.1562 - categorical_accuracy: 0.9510 - f1: 0.9523\n",
      "Model saved in model_v3_1\n",
      "Epoch 129/134\n",
      "50/50 [==============================] - 2881s 58s/step - loss: 0.1913 - categorical_accuracy: 0.9464 - f1: 0.9448\n",
      "Model saved in model_v3_2\n",
      "Epoch 130/134\n",
      "29/50 [================>.............] - ETA: 16:30 - loss: 0.1328 - categorical_accuracy: 0.9625 - f1: 0.9632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-23e8ac2c8bf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m103\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_from_n_epoch(103, 'model_v3_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 130/134\n",
      "50/50 [==============================] - 3144s 63s/step - loss: 0.1438 - categorical_accuracy: 0.9572 - f1: 0.9581\n",
      "Model saved in model_v3_0\n",
      "Epoch 131/134\n",
      "50/50 [==============================] - 2814s 56s/step - loss: 0.2085 - categorical_accuracy: 0.9389 - f1: 0.9395\n",
      "Model saved in model_v3_1\n",
      "Epoch 132/134\n",
      "50/50 [==============================] - 2674s 53s/step - loss: 0.1516 - categorical_accuracy: 0.9506 - f1: 0.9504\n",
      "Model saved in model_v3_2\n",
      "Epoch 133/134\n",
      "50/50 [==============================] - 3194s 64s/step - loss: 0.1086 - categorical_accuracy: 0.9658 - f1: 0.9658\n",
      "Model saved in model_v3_0\n",
      "Epoch 134/134\n",
      "50/50 [==============================] - 2996s 60s/step - loss: 0.1236 - categorical_accuracy: 0.9660 - f1: 0.9640\n",
      "Model saved in model_v3_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e037426198>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_from_n_epoch(129, 'model_v3_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on last images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/135\n",
      "39/39 [==============================] - 2169s 56s/step - loss: 0.1308 - categorical_accuracy: 0.9579 - f1: 0.9555\n",
      "Model saved in model_v3_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e03e2f32b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_i = 134 * 50 + 1\n",
    "hist = History()\n",
    "model = load_model('model_v3_1', custom_objects={'f1':f1})\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(12, augment=True), \n",
    "    steps_per_epoch=39,\n",
    "    epochs=135,\n",
    "    callbacks=[ModelSaveCallback(MODEL_FNAME), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=134\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2546, 75052,  8075,  7028,  7130,  7259,   106,   472],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, counts = np.unique(labels, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_on_subset(load_fname):\n",
    "    global indices\n",
    "    \n",
    "    indices = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        indices.extend(np.random.choice(np.where(labels == i)[0], size=min(3200, counts[i])))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    batch_i = 1\n",
    "    hist = History()\n",
    "    model = load_model(load_fname, custom_objects={'f1':f1})\n",
    "    file_name = 'model_v4' + '_{}'\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_iterator(26, augment=True), \n",
    "        steps_per_epoch=61,\n",
    "        epochs=12,\n",
    "        callbacks=[ModelSaveCallback(file_name), hist],\n",
    "        verbose=1,  \n",
    "        class_weight=class_weights,\n",
    "        initial_epoch=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "61/61 [==============================] - 1606s 26s/step - loss: 0.1387 - categorical_accuracy: 0.9675 - f1: 0.9674\n",
      "Model saved in model_v4_0\n",
      "Epoch 2/12\n",
      "61/61 [==============================] - 1647s 27s/step - loss: 0.0828 - categorical_accuracy: 0.9812 - f1: 0.9807\n",
      "Model saved in model_v4_1\n",
      "Epoch 3/12\n",
      "61/61 [==============================] - 1562s 26s/step - loss: 0.0756 - categorical_accuracy: 0.9791 - f1: 0.9786\n",
      "Model saved in model_v4_2\n",
      "Epoch 4/12\n",
      "61/61 [==============================] - 1566s 26s/step - loss: 0.0692 - categorical_accuracy: 0.9832 - f1: 0.9832\n",
      "Model saved in model_v4_0\n",
      "Epoch 5/12\n",
      "61/61 [==============================] - 1599s 26s/step - loss: 0.0837 - categorical_accuracy: 0.9751 - f1: 0.9764\n",
      "Model saved in model_v4_1\n",
      "Epoch 6/12\n",
      "61/61 [==============================] - 1602s 26s/step - loss: 0.0662 - categorical_accuracy: 0.9818 - f1: 0.9815\n",
      "Model saved in model_v4_2\n",
      "Epoch 7/12\n",
      "61/61 [==============================] - 1704s 28s/step - loss: 0.0994 - categorical_accuracy: 0.9776 - f1: 0.9769\n",
      "Model saved in model_v4_0\n",
      "Epoch 8/12\n",
      "61/61 [==============================] - 1838s 30s/step - loss: 0.0590 - categorical_accuracy: 0.9870 - f1: 0.9872\n",
      "Model saved in model_v4_1\n",
      "Epoch 9/12\n",
      "61/61 [==============================] - 1616s 26s/step - loss: 0.0434 - categorical_accuracy: 0.9876 - f1: 0.9872\n",
      "Model saved in model_v4_2\n",
      "Epoch 10/12\n",
      "61/61 [==============================] - 1677s 27s/step - loss: 0.0860 - categorical_accuracy: 0.9811 - f1: 0.9816\n",
      "Model saved in model_v4_0\n",
      "Epoch 11/12\n",
      "61/61 [==============================] - 1606s 26s/step - loss: 0.0731 - categorical_accuracy: 0.9825 - f1: 0.9837\n",
      "Model saved in model_v4_1\n",
      "Epoch 12/12\n",
      "61/61 [==============================] - 1510s 25s/step - loss: 0.0850 - categorical_accuracy: 0.9750 - f1: 0.9756\n",
      "Model saved in model_v4_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28962e9b278>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_subset('model_v3_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights[6] = 10\n",
    "class_weights[7] = 2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "61/61 [==============================] - 1664s 27s/step - loss: 0.0511 - categorical_accuracy: 0.9864 - f1: 0.9873\n",
      "Model saved in model_v4_0\n",
      "Epoch 2/12\n",
      "61/61 [==============================] - 1891s 31s/step - loss: 0.0587 - categorical_accuracy: 0.9829 - f1: 0.9839\n",
      "Model saved in model_v4_1\n",
      "Epoch 3/12\n",
      "61/61 [==============================] - 1528s 25s/step - loss: 0.0652 - categorical_accuracy: 0.9803 - f1: 0.9803\n",
      "Model saved in model_v4_2\n",
      "Epoch 4/12\n",
      "61/61 [==============================] - 3068s 50s/step - loss: 0.0606 - categorical_accuracy: 0.9837 - f1: 0.9839\n",
      "Model saved in model_v4_0\n",
      "Epoch 5/12\n",
      "61/61 [==============================] - 2933s 48s/step - loss: 0.0509 - categorical_accuracy: 0.9865 - f1: 0.9857\n",
      "Model saved in model_v4_1\n",
      "Epoch 6/12\n",
      "61/61 [==============================] - 1701s 28s/step - loss: 0.0534 - categorical_accuracy: 0.9811 - f1: 0.9816\n",
      "Model saved in model_v4_2\n",
      "Epoch 7/12\n",
      "61/61 [==============================] - 1810s 30s/step - loss: 0.0540 - categorical_accuracy: 0.9870 - f1: 0.9866\n",
      "Model saved in model_v4_0\n",
      "Epoch 8/12\n",
      "61/61 [==============================] - 1868s 31s/step - loss: 0.0525 - categorical_accuracy: 0.9841 - f1: 0.9853\n",
      "Model saved in model_v4_1\n",
      "Epoch 9/12\n",
      "61/61 [==============================] - 1729s 28s/step - loss: 0.0587 - categorical_accuracy: 0.9814 - f1: 0.9817\n",
      "Model saved in model_v4_2\n",
      "Epoch 10/12\n",
      "61/61 [==============================] - 1862s 31s/step - loss: 0.0413 - categorical_accuracy: 0.9850 - f1: 0.9847\n",
      "Model saved in model_v4_0\n",
      "Epoch 11/12\n",
      "61/61 [==============================] - 1749s 29s/step - loss: 0.0486 - categorical_accuracy: 0.9876 - f1: 0.9871\n",
      "Model saved in model_v4_1\n",
      "Epoch 12/12\n",
      "61/61 [==============================] - 1896s 31s/step - loss: 0.0785 - categorical_accuracy: 0.9804 - f1: 0.9805\n",
      "Model saved in model_v4_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28900890a20>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_subset('model_v4_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "61/61 [==============================] - 1845s 30s/step - loss: 0.0434 - categorical_accuracy: 0.9876 - f1: 0.9881\n",
      "Model saved in model_v4_0\n",
      "Epoch 2/12\n",
      "61/61 [==============================] - 1721s 28s/step - loss: 0.0489 - categorical_accuracy: 0.9901 - f1: 0.9898\n",
      "Model saved in model_v4_1\n",
      "Epoch 3/12\n",
      "61/61 [==============================] - 1776s 29s/step - loss: 0.0572 - categorical_accuracy: 0.9827 - f1: 0.9841\n",
      "Model saved in model_v4_2\n",
      "Epoch 4/12\n",
      "61/61 [==============================] - 1828s 30s/step - loss: 0.0612 - categorical_accuracy: 0.9794 - f1: 0.9799\n",
      "Model saved in model_v4_0\n",
      "Epoch 5/12\n",
      "61/61 [==============================] - 1670s 27s/step - loss: 0.0292 - categorical_accuracy: 0.9915 - f1: 0.9912\n",
      "Model saved in model_v4_1\n",
      "Epoch 6/12\n",
      "61/61 [==============================] - 1688s 28s/step - loss: 0.0479 - categorical_accuracy: 0.9856 - f1: 0.9858\n",
      "Model saved in model_v4_2\n",
      "Epoch 7/12\n",
      "61/61 [==============================] - 1741s 29s/step - loss: 0.0610 - categorical_accuracy: 0.9828 - f1: 0.9835\n",
      "Model saved in model_v4_0\n",
      "Epoch 8/12\n",
      "61/61 [==============================] - 1498s 25s/step - loss: 0.0499 - categorical_accuracy: 0.9838 - f1: 0.9838\n",
      "Model saved in model_v4_1\n",
      "Epoch 9/12\n",
      "61/61 [==============================] - 1724s 28s/step - loss: 0.0627 - categorical_accuracy: 0.9804 - f1: 0.9804\n",
      "Model saved in model_v4_2\n",
      "Epoch 10/12\n",
      "61/61 [==============================] - 1785s 29s/step - loss: 0.0383 - categorical_accuracy: 0.9906 - f1: 0.9914\n",
      "Model saved in model_v4_0\n",
      "Epoch 11/12\n",
      "61/61 [==============================] - 1564s 26s/step - loss: 0.0391 - categorical_accuracy: 0.9888 - f1: 0.9894\n",
      "Model saved in model_v4_1\n",
      "Epoch 12/12\n",
      "61/61 [==============================] - 1617s 27s/step - loss: 0.0617 - categorical_accuracy: 0.9840 - f1: 0.9846\n",
      "Model saved in model_v4_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28902198160>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_subset('model_v4_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "61/61 [==============================] - 1709s 28s/step - loss: 0.0425 - categorical_accuracy: 0.9877 - f1: 0.9884\n",
      "Model saved in model_v4_0\n",
      "Epoch 2/12\n",
      "61/61 [==============================] - 1642s 27s/step - loss: 0.0319 - categorical_accuracy: 0.9905 - f1: 0.9909\n",
      "Model saved in model_v4_1\n",
      "Epoch 3/12\n",
      "61/61 [==============================] - 1699s 28s/step - loss: 0.0615 - categorical_accuracy: 0.9863 - f1: 0.9862\n",
      "Model saved in model_v4_2\n",
      "Epoch 4/12\n",
      "61/61 [==============================] - 1681s 28s/step - loss: 0.0302 - categorical_accuracy: 0.9917 - f1: 0.9919\n",
      "Model saved in model_v4_0\n",
      "Epoch 5/12\n",
      "61/61 [==============================] - 1749s 29s/step - loss: 0.0488 - categorical_accuracy: 0.9903 - f1: 0.9900\n",
      "Model saved in model_v4_1\n",
      "Epoch 6/12\n",
      "61/61 [==============================] - 1736s 28s/step - loss: 0.0538 - categorical_accuracy: 0.9862 - f1: 0.9863\n",
      "Model saved in model_v4_2\n",
      "Epoch 7/12\n",
      "61/61 [==============================] - 1709s 28s/step - loss: 0.0418 - categorical_accuracy: 0.9875 - f1: 0.9867\n",
      "Model saved in model_v4_0\n",
      "Epoch 8/12\n",
      "61/61 [==============================] - 1761s 29s/step - loss: 0.0474 - categorical_accuracy: 0.9858 - f1: 0.9863\n",
      "Model saved in model_v4_1\n",
      "Epoch 9/12\n",
      "61/61 [==============================] - 1819s 30s/step - loss: 0.0526 - categorical_accuracy: 0.9840 - f1: 0.9842\n",
      "Model saved in model_v4_2\n",
      "Epoch 10/12\n",
      "61/61 [==============================] - 1757s 29s/step - loss: 0.0300 - categorical_accuracy: 0.9904 - f1: 0.9901\n",
      "Model saved in model_v4_0\n",
      "Epoch 11/12\n",
      "61/61 [==============================] - 1869s 31s/step - loss: 0.0687 - categorical_accuracy: 0.9810 - f1: 0.9811\n",
      "Model saved in model_v4_1\n",
      "Epoch 12/12\n",
      "61/61 [==============================] - 1851s 30s/step - loss: 0.0788 - categorical_accuracy: 0.9790 - f1: 0.9789\n",
      "Model saved in model_v4_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2890806d9b0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_subset('model_v4_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "61/61 [==============================] - 1640s 27s/step - loss: 0.0688 - categorical_accuracy: 0.9805 - f1: 0.9796\n",
      "Model saved in model_v4_0\n",
      "Epoch 2/12\n",
      "61/61 [==============================] - 1814s 30s/step - loss: 0.0437 - categorical_accuracy: 0.9842 - f1: 0.9842\n",
      "Model saved in model_v4_1\n",
      "Epoch 3/12\n",
      "61/61 [==============================] - 1806s 30s/step - loss: 0.0485 - categorical_accuracy: 0.9885 - f1: 0.9895\n",
      "Model saved in model_v4_2\n",
      "Epoch 4/12\n",
      "61/61 [==============================] - 1696s 28s/step - loss: 0.0509 - categorical_accuracy: 0.9864 - f1: 0.9858\n",
      "Model saved in model_v4_0\n",
      "Epoch 5/12\n",
      "61/61 [==============================] - 1685s 28s/step - loss: 0.0449 - categorical_accuracy: 0.9836 - f1: 0.9840\n",
      "Model saved in model_v4_1\n",
      "Epoch 6/12\n",
      "61/61 [==============================] - 1780s 29s/step - loss: 0.0372 - categorical_accuracy: 0.9891 - f1: 0.9892\n",
      "Model saved in model_v4_2\n",
      "Epoch 7/12\n",
      "61/61 [==============================] - 1847s 30s/step - loss: 0.0513 - categorical_accuracy: 0.9849 - f1: 0.9847\n",
      "Model saved in model_v4_0\n",
      "Epoch 8/12\n",
      "61/61 [==============================] - 1828s 30s/step - loss: 0.0566 - categorical_accuracy: 0.9831 - f1: 0.9829\n",
      "Model saved in model_v4_1\n",
      "Epoch 9/12\n",
      "61/61 [==============================] - 1658s 27s/step - loss: 0.0563 - categorical_accuracy: 0.9848 - f1: 0.9851\n",
      "Model saved in model_v4_2\n",
      "Epoch 10/12\n",
      "61/61 [==============================] - 1765s 29s/step - loss: 0.0445 - categorical_accuracy: 0.9869 - f1: 0.9875\n",
      "Model saved in model_v4_0\n",
      "Epoch 11/12\n",
      " 3/61 [>.............................] - ETA: 29:16 - loss: 0.0340 - categorical_accuracy: 0.9905 - f1: 0.9855  "
     ]
    }
   ],
   "source": [
    "train_on_subset('model_v4_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7327801 , 0.37594672, 0.56126676, 0.66072376, 0.53450137,\n",
       "       0.46130008, 2.08951783, 0.94683388])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (np.subtract(1, f1_scores) + 0.5)** 2 \n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "61/61 [==============================] - 1673s 27s/step - loss: 0.0570 - categorical_accuracy: 0.9878 - f1: 0.9884\n",
      "Model saved in model_v4_0\n",
      "Epoch 2/12\n",
      "61/61 [==============================] - 1821s 30s/step - loss: 0.0557 - categorical_accuracy: 0.9850 - f1: 0.9852\n",
      "Model saved in model_v4_1\n",
      "Epoch 3/12\n",
      "61/61 [==============================] - 1649s 27s/step - loss: 0.0517 - categorical_accuracy: 0.9856 - f1: 0.9857\n",
      "Model saved in model_v4_2\n",
      "Epoch 4/12\n",
      "61/61 [==============================] - 1653s 27s/step - loss: 0.0522 - categorical_accuracy: 0.9841 - f1: 0.9844\n",
      "Model saved in model_v4_0\n",
      "Epoch 5/12\n",
      "61/61 [==============================] - 1575s 26s/step - loss: 0.0499 - categorical_accuracy: 0.9888 - f1: 0.9891\n",
      "Model saved in model_v4_1\n",
      "Epoch 6/12\n",
      "61/61 [==============================] - 1584s 26s/step - loss: 0.0885 - categorical_accuracy: 0.9775 - f1: 0.9783\n",
      "Model saved in model_v4_2\n",
      "Epoch 7/12\n",
      "61/61 [==============================] - 1565s 26s/step - loss: 0.0531 - categorical_accuracy: 0.9848 - f1: 0.9848\n",
      "Model saved in model_v4_0\n",
      "Epoch 8/12\n",
      "61/61 [==============================] - 1747s 29s/step - loss: 0.0495 - categorical_accuracy: 0.9860 - f1: 0.9862\n",
      "Model saved in model_v4_1\n",
      "Epoch 9/12\n",
      "61/61 [==============================] - 1599s 26s/step - loss: 0.0520 - categorical_accuracy: 0.9848 - f1: 0.9839\n",
      "Model saved in model_v4_2\n",
      "Epoch 10/12\n",
      "61/61 [==============================] - 1514s 25s/step - loss: 0.0636 - categorical_accuracy: 0.9854 - f1: 0.9847\n",
      "Model saved in model_v4_0\n",
      "Epoch 11/12\n",
      "61/61 [==============================] - 1599s 26s/step - loss: 0.0439 - categorical_accuracy: 0.9889 - f1: 0.9889\n",
      "Model saved in model_v4_1\n",
      "Epoch 12/12\n",
      "61/61 [==============================] - 1533s 25s/step - loss: 0.0701 - categorical_accuracy: 0.9842 - f1: 0.9845\n",
      "Model saved in model_v4_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac87c44ba8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_subset('model_v4_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each training stage quality metrics are saved in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('f1_scores.txt', 'a') as fout:\n",
    "    for val in hist.history['f1']:\n",
    "        fout.write(str(val) + '\\n')\n",
    "        \n",
    "with open('cat_accuracies.txt', 'a') as fout:\n",
    "    for val in hist.history['categorical_accuracy']:\n",
    "        fout.write(str(val) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure quality of trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_iterator(paths_test):\n",
    "    for i in range(len(paths_test)):\n",
    "        image = cv2.imread(paths_test[i], cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.expand_dims(image, -1)\n",
    "        yield np.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 5, 1, 2, 1, 1, 0, 1, 5, 1], 107668)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test = []\n",
    "for path in all_paths:\n",
    "    img_n = path[path.find('\\\\') + 1 : path.rfind('.')]\n",
    "    labels_test.append(n_l[img_n])\n",
    "    \n",
    "labels_test[:10], len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107668/107668 [==============================] - 23058s 214ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(predict_iterator(all_paths), steps=len(all_paths), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 1, 2, 1, 6, 0, 1, 5, 1], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = np.argmax(preds, axis=1)\n",
    "labels_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate confusion matrix and f1-score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_mtx = confusion_matrix(labels_test, labels_pred, labels=np.arange(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APC', 'NOR', 'LBB', 'PAB', 'PVC', 'RBB', 'VEB', 'VFW']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    x.append(idx_to_class[i].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEyCAYAAAAofq3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd8zdcfx/HXJzdBxAoRM0bMUooG\nNWrU3pRSyi81Ss1W1QqaxohVtYqipbYidmsXRalRtbU2QWLPJOTenN8f90qD5CbS3Nzb5Dw9vg/3\nnvsd73zvOPec873fryil0DRN0zRbcLJ3AE3TNC3l0pWMpmmaZjO6ktE0TdNsRlcymqZpms3oSkbT\nNE2zGV3JaJqmaTajKxlN0zTNZnQlo2maptmMrmQ0TdM0m3G29QYCAgL0KQU0TUux/P39JanW5Zwm\nT6I+L41PryZZhqRm80oG4LPre5NjM6/s61yV8OvZwd4xYhU4bYHOlgg6W+I4fLbu7ewdI1aBMxbb\nO4LDS5ZKRtM0TYufwzZH/gVdyWiapjkIkZRXzehKRtM0zUHoSkbTNE2zGUmBHWa6ktE0TXMQKbEl\no38no2ma5iCcRBI1xUdEionInzGmByLyqYh8KSJXY5Q3jLHMYBE5KyJ/iUi9GOX1LWVnRWRQfNvW\nLRlN0zQHYavuMqXUX0AZABExAFeBVUBHYKJS6qvncoiUAN4HSgK5ga0iUtTy8DSgDhAMHBCRtUqp\nk3FtW1cymqZpDiIhrZIkUAs4p5S6ZKV7rhmwVCn1BLggImeBCpbHziqlzgOIyFLLvHFWMrq7TNM0\nzUGISGKnriJyMMbU1cpm3geWxLjfS0SOisgcEXG3lOUBrsSYJ9hSFld5nHQlo2ma5iCckERNSqlZ\nSimfGNOs2NYvImmApsByS9EMoBDmrrTrwIRns8ayuLJSHifdXaZpmuYgkuHosgbAH0qpUIBn/1u2\nPRtYb7kbDHjFWC4vcM1yO67yWNm9khF3D9J92B/J5A5KEbn7ZyJ/WRP9uEudlqRr+RGP+rVGPX4A\ngKFoadK+1w0MzqhH9wn/eoB53nea4VKlAYgQuXsDkb+stlnuoYFf8+ue/WR1z8Lqhd8CMHXWfH7Z\nvRcncSKre2ZGDemHZ/ZsNssQnydPnuLbsz9PIyMxGU3UqVmVXl3se36q2PZbv2GjuXg5GICHjx6R\nMUMGguZNs2dMh9x3z8S2Dx3JgmWrCVq7EaUUrZrWp0ObFnbL8uTJU3x7D+Tp00hMpijq1KhCr84f\nsDhoHQuWr+XK1evsWrcI9yyZ7ZYxpmQYk2lLjK4yEcmllLpuudsCOG65vRZYLCJfYx74LwLsx9yS\nKSIiBTEfPPA+YPXEcnavZDBF8WTFbKKunIW0rrj5TcV06jBR1y8j7h44Fy9H1O3Qf+Z3dSNt256E\nTxmKunsTyWh+cTjlzo9LlQaEjfkETJG49h6F8fh+1A2rlWyiNW9Yh3Ytm+I34p+DMjp+0JLeXf8H\nwMLla5gxdzH+A3rbZPsJkSaNC3OmjCF9elcijUb+1/1z3n7Lhzdef81umWLbbxNGDI6+PX7qbDK4\npbdHtOc44r57JrZ96CjOnL9I0NqNLPluEi7OLnzcbyjVKlcgv5fVbnubSZPGhTmTAv95HnsM4O23\n3qRsqRJUr1yBjn0Gx7+SZGTLloyIpMd8VFi3GMXjRKQM5i6vi88eU0qdEJFlmAf0jUBPpZTJsp5e\nwCbAAMxRSp2wtt04x2REJLvlMLYXy0uKSPZX+NusUg/umCsYgCfhmEKuIFnM3/7TvteNJyu/e25+\nlwo1MR7+DXX3pnn5h/cBcMqZD9OF0xD5BKKiMJ05hkuZykkV8yU+ZUqROVPG58oyuLlF3w4Pj8De\nv6sSEdKndwXAaDRiNBrt/mOv2PbbM0opNv7yKw3r1EjeULFwxH33jLV9aG/nL16hdMniuKZLh7Oz\nAZ8ypdj26292y/Py82hCEF4rWog8uXLYLVdcEjsmkxBKqTClVDal1P0YZR2UUqWUUqWVUk1jtGpQ\nSo1SShVSShVTSm2IUf6zUqqo5bFR8f9NcZsKxFaZ5AUmJ+ivekWSLQcGr0KYLvyFofRbqHu3ibp6\n4bl5nDzzIOkz4PrZONIPnopzxVoARF27iHOR18EtI7ikxfn18oh7ktWFCTZ55g/UatGBnzZvd4ju\nFZPJREvfnlRr3JZK5ctSumRxe0eK06Ejx8nm7m63b70v+i/tO0dR2Ds/h44c5979B4RHRLBr7wFC\nQm/aNZPJZKJlx95Ua9qeSuXLULpkMbvmsSaxR5c5MmuVTCml1M4XC5VSm4DS1lYa83C6gwcPJixJ\n2nS4dh3Kk2UzwWQibYP3ebJ2/svzGQwY8hUm/JthhE8ZQtpG7RDPPESFXOHppuWk/2Q0rn1GYgo+\nD1GmhG07CX3S7UO2rVpAo7o1WRy0Ltm3/yKDwUDQvGlsW7WAYyf/5sz5i/aOFKeft+ygYZ3q9o4R\n7b+07xxFoQL56PTBe3z0qR8ffzaMooW9MRgMds1kMBgImjuVbUE/cOyUYz+Pksh/jsxaJeOSyMee\nO5zOx8cnASkMuHYdRuT+7Rj/3INT9lxItpy4DZuB26h5SBYP0g/5Bsnkjrp7C+PJQ/D0CerxA4xn\njmPI6w1A5G+bCAvsRfiE/qjHD4my0XhMQjSqW4OtO/bYbfsvypQxA+XLlWb3vgRW+snMaDSxdedv\n1K9Vzd5RXuLo+87RtGxSj+Vzv2He9PFkzpTRYVqmmTJmoHzZUuz+/Q97R0lVrFUyZ2Kex+YZEWkA\nnE/KEOn+15eokMtEblsJmLu+Hg94n8dDfHk8xBd17xZho3qhHtzFeGQvhsIlwckJXNJiKFCMqJDL\n5myWgwDEPTvOZasQeWBHUsaM16UrV6Nvb9+1j4L58ybr9l905+49Hjx8BEDEkyfsO3CYgvm94lnK\nPvYdPIx3/rzk9Ez+Ls7Y/Jf2naO5ffceANdDbrBt5x4a1LZf6/TO3fvPP48H/6RgPvu+L62x1bnL\n7Mna0WV9gfUi0ho4ZCnzASoBjZMqgKFQSVzeqo0p+ALph5gPW32y5gdMxw/EOn9UyBWMJw6RftgM\niFJE7tlI1LVLAKTrOgzJkBFMJp4smQZhj5Iq5kv6+4/hwOGj3Lv3gFrN29Ojcwd27T3AxcvBiJOQ\nO6cnX/S335FlADdv32XIyK8wRUWhohT13nmbGlUq2jVTbPutZZN6bNi6kwa1a9g1W0yOuO+eiWsf\nOoq+fiO59+ABzs7ODOnXw64HKdy8fYchgRMxmaJQKop6Nd+mRpUKLFyxlrmLg7h15y7vftibt9/y\nYfigPnbL+Yyjj68kRpyVjFLqbxEphfkY6NctxTuBbkqpiKQKYDp3gocf17c6z+Mhvs/dj9yygsgt\nK16aL3zC50kVK17jA14++agjvdEBihUuyIof7Pt7kxfFtt8ARg3tl8xJrHPEffdMXPvQUcyf4TiH\nVhcrXJAVc6a8VN6+VVPat2pqh0TWJfRIsf+S+H4n0wDIBmy2DPhrmqZpNpKqWjIiMh3zaZ5/A0aI\nSAWl1IhkS6ZpmpbKpLaWTDXgDaWUyfJL0V2ArmQ0TdNsRCTlnbPYWiXz9NlpBJRSYZIS23GapmkO\nxNF/85IY1iqZ4iJy1HJbgEKW+wJEKaXesHk6TdO0VMTRD0dODGuVTGxnAhTMp5Xxs00cTdO01CtV\ntWSUUpee3bacpbMd0Bq4AATZPpqmaVrqkqpaMiJSFPO1AtoCt4EfAVFK1UymbJqmaalKqmrJAKcx\nH1HWRCl1FkBE+iZLKk3TtFQoJbZkrB0v1xIIAbaLyGwRqUXs13fWNE3TkkCqOguzUmqVUqoNUBzY\ngflcZjlEZIaI1E2mfJqmaalGSjxBpiilEj6zSFbgPaCNUuqdhCwTEBCQ8A1omqb9x/j7+yfZp/wb\nOSsn6vPySMhvDlvTxHfusucope4AMy2TpmmaloRS22llksxg30bJsZlXNnreT4wYNcveMWI1bEhX\nBndoYO8YsRq9YAODP2xi7xixGv3DOga1d6yzYT8zZuEmh34v+PW0/+XCYxM4bQF+3dvZO0asAmcs\ntncEh5cslYymaZoWv5R49i5dyWiapjkI3V2maZqm2YxuyWiapmk24+i/eUkMXclomqY5CN1dpmma\nptmM7i7TNE3TbEa3ZDRN0zSb0ZWMpmmaZjMpr4rRlYymaZrDcPSTXSaGrmQ0TdMchD6E2cZCbtzG\nb/wMbt29j5MIrRq+Q/sW9fl81BQuBl8H4OHjMDK6pWfFjNH8dugYk+YsJdJoxMXZmX4ftaNimZL/\nKkPRooVYvGhG9H3vgvn4MuArsmVzp0mTukRFKW7euEWnLn25fj0UgOrVKjFhQgAuLs7cvnWHd2q3\nAmD2rAk0alibGzdvUaZsreh1jh09lEaN6/D06VPOn79E5y6fcf/+g0RnDrl5G7+vZv6z3xrUpH3z\nevx1/hLDp/5AWEQEeTw9GDOgBxncXIk0Gvly0vecPHcRkymKprWq0KVN00Rv32q2G7fxGz+dW3fu\n4eQktGpYi/YtGrDp133MWLCC85evsWTqCEoWLQTA+m27+WH5+ujl/75wmWXTAyleqECSZ3vy9Ckd\nBwTyNNKIyWSidtXy9Gz/LoPGfcuJMxdwdjZQqqg3w3p/iIuz+a1y4Ogpxs1ajNFoJEumjMwd55fk\nuSDu98L0BUEEbdiOe+aMAPTp2IZqFcoA8N3SNazcuBODwYlB3f9HFZ/SNskW0/XQm/iN+Ipbd+6a\nczZrQIfWzTl95jwjxk8lLDyC3Lk8Ges/gAxubjbPExuTyUSbj/ri6ZGN6eP82XfwTyZMn0uUiiK9\nqyuj/D4lX97cdsn2Ij0mY2MGgxOfd/2AEkUK8jgsnDa9hlKp3Ot8NaRP9DzjZy4kg1t6ANwzZ+Sb\n4Z/jmc2dMxev8LHfWLYt/uZfZfj773P4lDdfLsfJyYnLFw+xes0G7t69j/+X4wHo1bMTQ4f0pWev\nQWTOnImpUwNp1PgDrly5Rvbs2aLXNX/+MqZPn8vcuZOf28bWbb/iN3Q0JpOJ0YF+DBrYi8F+gYnO\nbDAY+PyjdpQoXMC83/p8QaWyr+M/6Xv6dWlL+dKvsWrTTuYG/UTv/7Vi8679PI2MZNWM0YRHPKF5\nt0E0qFGJPDmyJzpD3Nmc+Lxr+3+e055+VCpXiiIFvJj4xWcMn/zdc/M3rlWVxrWqAuYKpo//BJtU\nMABpXFz4bvQg0rumI9JoxPfzUVT1KU2jmpUY3b8bAAPHzWDlpp20aVSLB48eM2rafGaM+Jxcntm4\nfS/xXwziE9d7AaBDiwZ8+N7zJ9o8dymYDTv2sXrWWG7cuctHg0az/vsJGAzWrkv47zkbDPTv/REl\nihXm8eMwWnfuQ+XyZfEfM4nPe3WhfNnSrFy/ibmLgujd9X82zRKXhcvX4p3fi0ePwwAYMWE6U0YP\no1ABL5au+omZ835k1BDHuOhvSjyE2bavwFeUPZs7JYoUBMAtvSsFvXITeutu9ONKKTb9+jsNa1YG\n4LXCBfDM5g5A4fx5efI0kqdPI5MsT613qnL+/CUuX77Kw4ePosvd3NLz7Do8bd9vwerVG7hy5RoA\nN2/ejp5v1+7fuXP33kvr3bL1V0wmEwD7fv+DPHly/auc2bNmoUThAuZsz/bb7TtcDL6OT6niAFQq\n9zpbdx8AzC/k8IgnGE0mnjx9iouLMxnSu/6rDHFme/E5zZeH0Ft38M6Xh4Je1r89btj+W/RzbQsi\nQnrXdAAYjSaMJhOC8Hb5NxARRIRSRb2jX4M/79hHrcpvksvT/EUiW5ZMNssW33vhRdv3HqJBjbdI\nk8aFvDk9yZc7B8f+OmezfNE5PbJSolhhc0639Hjn9yL05m0uXg7Gp0wpACqVL8eWnbttniU2ITdu\n8eveA7Rs/M91FkWEx5YK5+Gjx2T3yGqXbLFxQhI1ObJEVTIiUkxEZid1mJiuhtzk9LlLlC5eKLrs\n0PHTZHPPTP48OV+af8vu/RQvlJ80aVySLEPr1s1Y+uPq6Psjhg/kwrkDtG3bgi8DzK2aIkW8yZIl\nM9u2LOf3fRto377VK22j44fvs3HT9iTLfDXUst+KFaZwgbxs3/cHAJt27Sfk1h0A6lQtj2u6tLzT\nrjd1//cpvu82IHPGDEmWIc5sITc5ffYipYsXTtD8G3fupUEN21UyACZTFO/1GkaNdr2pVLbkc6+3\nSKORdb/8RpU3zR+Wl66G8OBRGJ0GjqZNny9Yuy15PjhffC8sWbeZdz8exLAJs7j/8DEAobfukiNG\nKzqHR1Zu3L6TLPmic14P5dSZc5QuWYzC3gXYvnsfAJu37yIk9FayZnlm7JRZfNajE+L0zwdxwMDe\ndB/wJbXe9WXdpu10af+eXbLFJlVdfhlAREqLyGYROS4iI0Ukh4gEAduAk1aW6yoiB0Xk4MGDB185\nVFh4BH1HTGLgxx2iu8YANmzfS8MalV6a/+zFYCZ+vxT/Tzq/8rbi4uLiQpPGdVkR9M/4wLAvxlKw\nUHmWLFlFzx4dAXB2NvBmudI0afY/GjZqx5DBn1KkiHeCtjF4UB+MRiOLF69Mksxh4RH0HTmFgd0+\nIIObK8P7fsTSdVtp3XsYYeHh0eMKx/86j5OTE9sWTWHDD18zf+UGrly/kSQZrGYbPpGB3f/33HMa\nl6OnzpIubVqKFPSyaS6DwYnl34xgy/yJHP/7PGcuBkc/NmrafN58vRhvvl4MMPftnzx7kW8CPuPb\nEf2ZtWQtF4NDbJrvxfdC68a1+XnuRFZMDyR71ix8NWsRAIqXL6iYnB8+YWHh9B0ykoF9upHBzY0R\nfn1ZErSO1p168zgsHBeX5O+Z37FnP1nds1Cy2PNfauYvW8OMcV+ybeU8mjeszbip38WxhuTnlMjJ\nkcX3zM8GZgB7gfrAH8Bi4AOlVERcCymlZgGz4NUvvxxpNNJ3xCQavVOF2lXLR5cbTSa27jnAj9+M\nfG7+kJu3+XT4RAL7f4xX7hyvsimr6tevyeHDx7hx4+VvYEuWrmLtmvkEDJ/A1avXuX37DmFh4YSF\nhbNr9z5Kly7BmTPnra6/Q4f3aNSwNnXqtU6SvJFGI31HTqFRzcrUrmLeb95euZkVOBCAi8HX+XX/\nEQB+2vEbVX1K4+LsTLYsmSlToignzlzAK5dnkmSJNdvwiZbntEKCltmww7ZdZS/KlMENn1LF2XPo\nKEUK5GXGolXcvf+QL3p/GD1PDo+sZMmUkfTp0pI+XVrefL0Yf1+4TIG8L7esk0Js7wUP98zRj7ds\nUJNeX3wFQE6PrITG6KoNvXWH7JauZFuLNBr5dMhIGtWtSZ0aVQDwzu/F7EnmccaLl4P59bf9yZIl\npsPHTrJjz+/s2neQJ0+f8vhxON37f8mFy8GULmn+4tCg1tt06+ef7NlSk/gqwbRKqR+UUn8ppSYD\nUcAgaxXMv6GUwv/r2Xh75cG3ZcPnHtv3x3EKeuUmZ4wugQePHtNz2Fd80rENZS0vmqTyfpvmz3WV\nFS5cMPp2k8Z1+cvS37123SaqVqmIwWDA1TUdFSqU5fTpM1bXXa9uDfp/3oPm735IePi/35VKKfwn\nfYe3V2583/3napq3790HICoqillL19C64TsA5Mruwe9HTqKUIiwigqOnz1LQ69+NC1nN9vUsvPPl\nxrdVwq4KGRUVxeZdv1M/llZrUrpz/wEPHpm7myKePGXfnycpmDc3QRt38Nsfxxk7sDtOTv+8RWq+\nVY4/TvyN0WQiPOIJR/86F++4UmLF9V64efufcZltvx2kcIG8ANR460027NjH06eRBIfc4NLVEEoV\nK/TSem2R84vRk/DO74Xv++9Gl9+2jEVGRUUxc95SWjdvGNcqbKbvxx+ybeU8Ni+fw/gvB1ChXGmm\njh7Go8dhXLx8FYDfDvyJdwHbtpZfxbOxwFedHFl8LZl0IlKWf36I+ggoLZa/Sin1R1KGOXzib9Zt\n202Rgl606j4Y+OcQzQ07X+4qW7J2M1euhTJz8SpmLl4FwMzRg8iWJfNL634Vrq7pqF2rGt17DIwu\nCxw1mKJFCxEVFcXly1fp0XMQAKdPn2XT5u0c/mMrUVFRzJmzhBMn/gJg4YJpVK9WCQ+PrFw8f5CA\n4V8x94elTJ40krRp07Jxw1IAfv/9D3r2GpTovOb9tociBbxo1XMIAH183+PytVCWrt8KQK3KPjSv\nWw2Atk1qM/TrWbT4eDBKKZrXrUaxgvkSvX3r2f5i3dZd5uf0Y/Pf2KdTGyKfGgmc/gN37z+gx9Bx\nFC9UgJmjzc/5oWOnyemRFa9cSdcyjc2tO/cYOmE2pqgoopSi3tsVqF6xDGUbdySXZzY69BsBQK3K\nb/Jxu+Z458tNlTdL0arHUMRJeLdedYpYPuSTWlzvhQ07fuP0uUuICHlyZOeLPp0AKFwgL/WqVaRZ\n1wE4GwwM6fWhzY8sAzh89ATrNm6jSKECtPTtCcAn3Xy5FHyNpSvNXc21q1emRaO61laTbJydDXw5\noBd9hwUiImTKmIERgz+1d6xojj6Inxjy7CipWB8UsTYirZRS78S3gYCAAOXI1zUfMWqWvWPEatiQ\nrgzu0CD+Ge1g9IINDP6wib1jxGr0D+sY1L6evWPEaszCTTjye8GvZwd7x4hV4LQF+HVvZ+8YsQqc\nsRh/f/8kqxma5Gv8SsMLz6y7vN5hayerLRmlVM3kCqJpmpbaOfogfmLEe8iHiHgCPYGSgMJ8VNk0\npZRtD0fSNE1LZVJid1l8hzBXAQ5Y7s4HFlpu77c8pmmapiWRlDjwH1/rbALQXCnlr5Raq5Rao5Ty\nB5oDX9s+nqZpWuphy9/JiEgWEVkhIqdF5JSIVBKRrCKyRUTOWP53t8wrIjJFRM6KyFERKRdjPb6W\n+c+IiG9C/iZrMimlDr9YqJT6E8iYwL9N0zRNSwAb/+J/MrBRKVUceAM4BQwCtimlimD+kf2zw1wb\nAEUsU1fMv5dERLIC/kBFoALg/6xiikt8lYzEtgLLhlLiGJWmaZrd2OrcZSKSCagGfA+glHqqlLoH\nNAPmWWabh7mXCkv5fGW2D8giIrmAesAWpdQdpdRdYAvmH+pb+ZusmwhsFpHqIpLRMtUANlge0zRN\n05JIYrvLYp7KyzJ1fWHV3sBNYK6IHBaR70TEDcihlLoOYPn/2Wk/8gBXYiwfbCmLqzxO8R3CPEtE\nrgEjMB9dBnACGKmUWmdtWU3TNO3VJPZ8czFP5RUHZ6Ac0Fsp9buITOafrrHYo8SyGSvlVjdslVJq\nPbA+vvk0TdO0f8eGhzAHA8FKqd8t91dgrmRCRSSXUuq6pTvsRoz5Y55vJy9wzVJe44XyHdY2bLWS\nEZEvrDyslFIjrC2vaZqmJZytqhilVIiIXBGRYkqpv4BamH/zeBLwBcZY/l9jWWQt0EtElmIe5L9v\nqYg2AYExxurrAoOtbTu+lszjWMrcgM5ANszdaJqmaVoScLLtb156A4tEJA1wHuiIeUhnmYh0Bi4D\nzy6u8zPQEDgLhFnmRSl1R0RG8M/vJ4crpaxeuMjqucuem1EkI/AJ5gpmGTAhIb/6f9VT/Wuapv2X\nJOW5yzoWaJmoz8u5F4Mc9heZCTmtTFbgM+ADzIe4lbMcupZgDn3iPQfO5sgn73Tk/aazvTqdLXEC\npy1I0vU5+lUuEyO+MZnxwLuYj1oopZR6ZG1+TdM0TYspvt/J9ANyA0OBayLywDI9FJEHto+naZqW\neqS6yy8rpRw9v6ZpWoqR6rrLNE3TtOSTEr/V60pG0zTNQaTE68noSkbTNM1BpLwqRlcymqZpDkO3\nZDRN0zSb0WMymqZpms3oo8s0TdM0m9EtGU3TNM1mUl47RlcymqZpDkMP/NvRg4eP8B8zibPnL4EI\nI/z6Uub11+wdC4C6LX1xS58eJycnDAYDy+ZMSZbtftLnIzp1aotSiuPHT9O5y2fkyuXJ4oXTcXd3\n5/Cfx/D9sA+RkZGkSZOGH+ZOplzZUty5c5e2H3Tn0qVgyvuUYcaMcQCICMNHTGDNmo02yzw08Gt+\n3bOfrO5ZWL3w2+jyRcvXsCRoHQaDgWqVK9CvZ2ebZUgoez2vCbF730HGTPoWU1QULZvUp0uH1nbJ\ncT30Jn4jvuLWnbs4idCqWQM6tG7Opl92Mf37hZy/dIUlsyfx+mtF7ZIvttfb6TPnGTF+KmHhEeTO\n5clY/wFkcHOzS74X6e4yOxoz6VuqVPRh4qihREZGEh7xxN6RnjNn6hjcs2ROtu3lzp2TXj07UeqN\nmkRERLBk8be0ad2MBg3eYdKU2SxbtpZp34yhU8e2zJw1n04d23L37n2Kl6hK69ZNGR04hHYfdOf4\nidNUfKsBJpOJnDk9+ePgFtav34LJZLJJ7uYN69CuZVP8RnwVXbb/0BG2797HyvnTSZMmDbfv3rPJ\nthMjuZ/XhDCZTIycMI3ZkwLJ6elBmy6fULNqRQoVzJ/sWZwNBvr3/ogSxQrz+HEYrTv3oXL5shT2\nzs+kwGEEjLdvxRzb681/zCQ+79WF8mVLs3L9JuYuCqJ31//ZMeU/Ul475j9ScT56/JhDR47Tskk9\nAFxcXMiUMYOdU9mfs7Mzrq7pMBgMpHd1JSQklJo1qhAU9BMACxYsp1lT8z5r2qQuCxYsByAo6Cfe\nqVkVgPDwiOgKJV26tCT0+kKJ5VOmFJkzZXyu7MfVP9G5fWvSpEkDQDb3LDbN8F937NTf5MubG688\nuXBxcaFBrer8smufXbJk98hKiWKFAXBzS493fi9Cb96mUIF8FMyf1y6ZYort9XbxcjA+ZUoBUKl8\nObbs3G2PaLFyQhI1ObJ4KxkRyS8iHpbbb4nI5yLSwvbR/hF8NQT3LJkZOuprWn3Yky9GTyIsPCI5\nI1glInTtO4TWnXqzfM3PybLNa9dC+Hrit1w4t5/gy4e5/+ABh/44yr1796MrjeCr18mdJycAufPk\n5ErwNcD8Tfj+/Qdky2a+gmqF8mU58ucv/PnHNnr0GmSzVkxcLl6+yqEjx2n70ad82LM/x079lazb\nj4s9nteEuHHzFjk9s0ffz+HpwY2bt+2YyOzq9VBOnTlH6ZLF7B3FqsLeBdi+21wpb96+i5DQW3ZO\n9I+UeBZmq/lEZBjwC7BPREbMBe/TAAAgAElEQVQCkwAPoI+ITLKyXFcROSgiBw8ePPivQxpNJk79\nfZY2LRqx4odpuLqm4/sFy/71epPKghkTWD73G2ZMGMGSles5+Ocxm28zS5bMNG1Sj8JF38Irfznc\n3NJTv/47L833rGUisVzW9VmjZf+Bw7xR5h3eqtyQQQN6kTZtWptmf5HJZOLBw0csnjWRfj278Pmw\n0TZvUSWEPZ7XhIht19j2qr3xCwsLp++QkQzs081hxjfiMsKvL0uC1tG6U28eh4Xj4uI4owaSyMmR\nxVcJtgVeA3yAPsA7SqlBQB2gdlwLKaVmKaV8lFI+Pj4+/zpkTk8PcmT3oHTJ4gDUrVGVk3+f/dfr\nTSqe2bMB5m6eWtUqc+yk7b+J16r1NhcuXubWrTsYjUZWrd5Apbd8yJIlMwaDAYC8eXJx/VooAFeD\nr+OVNzcABoOBzJkzcefO8xc4PX36LI8fh/N6Mn8TzeHpQe3qVRARSpUohohw9979ZM0QG3s8rwmR\nw9ODkBs3o++H3rhFdo9sdssTaTTy6ZCRNKpbkzo1qtgtR0J55/di9qRAls2ZSsPa1fHKk8vekaKl\nxu6yCKXUU6XUPeCcUioMQCllBJ7aPJ2FR7as5PTMzoVLwQDsO/QnhQrkS67NWxUWHsHjx2HRt3/b\n/wdFvAvYfLtXLl+lYsVyuLqmA+CdmlU5depvduz8jZYtGwHQocN7rF23GYB16zfTocN7ALRs2Yjt\nO/YAUKCAV3SllC9fHooW9ebipSs2zx/TO29XYv+hPwFzf3mk0Wj3wXZ7Pa8J8XrxolwOvkbwtRAi\nIyPZsG0nNau+ZZcsSim+GD0J7/xe+L7/rl0yvKpnB5ZERUUxc95SWjdvaOdEKVt87cQsIvIu5hZZ\nJsttLPeT9VPAr293BgaMI9IYiVfuXIzw65ucm4/T7Tt3+cRvBAAmo4mGdWtQ9a1/33qLz/4Dh1m5\n8icO7N+E0Wjkzz9PMPu7Rfy8YRuLF05n+JcD+PPICebMXQLAnLlLmffDFE6f3M3du/do174HAFWq\nVGBA/55ERhqJioqiVx8/bt++a23T/0p//zEcOHyUe/ceUKt5e3p07sC7jesyNHAizdt/jIuLM4FD\n+8XavZec7PW8JoSzswG/vt3p9tlQTCYTLRrXpbB38h9ZBnD46AnWbdxGkUIFaOnbE4BPuvnyNDKS\n0RNncOfefXr096d4EW9mTRyV7Plie72FhYezdOV6AGpXr0yLRnWTPVdcnOzfS5zk4qtkdgJNLLd/\njXH72f1kU7xoIYf6ncIzXnlysXLedLtsO2D4BAKGT3iu7MKFy1Sq0vileZ88ecL7bbu9VL5oURCL\nFgXZLOOLxgcMirV8rP+AZMuQEPZ8XhOiWuUKVKtcwd4xKPfG6xzfsyHWx2pXt3/XWVyvtw6tmydz\nkoRx9EH8xIjv8ssdkyuIpmlaaufYoyuJE+9hFSJSHbirlDoqIq2BasA5YLpSyrF+EalpmvYflupa\nMiIyDSgNpBORv4AMwEagMjAH+MDmCTVN01IJRz9SLDHia8nUVEqVEJF0wFXAUyllEpGZwFHbx9M0\nTUs9Ul4VE38lEwGglIoQkUtKKZPlvhKRSJun0zRNS0VSXXcZ4Ckin2GuYJ/dxnI/e9yLaZqmaa8q\nNR7CPBvIGMttgO9skkjTNC2VSnXdZUqpgLgeE5FPkz6Opmla6pUSu8v+zd/0WfyzaJqmaQmVEs/C\n/G9OP5oSW3aapml2kxrHZKxJgbtD0zTNflLiN3exdt0OEXlI7JWJAK5KqXgrqYCAAF0ZaZqWYvn7\n+ydZ3TDdq32iPi97XFnosPVTfAP/Ga09nlB+PTskxWqSXOC0BTpbIgROW8Cib9bZO0asPujVxKH3\nm8726hw9W1Jy9PGVxHCcS8JpmqalcpIC+31SYsWpaZqmOQjdktE0TXMQKfFbv65kNE3THISuZDRN\n0zSb0b+T0TRN02zGYY9D/hd0JaNpmuYgdHeZpmmaZjMpsbssJVacmqZp/0mSyClB6xYxiMhhEVlv\nuf+DiFwQkT8tUxlLuYjIFBE5KyJHRaRcjHX4isgZy+SbkO3qloymaZqDcLLtKSE/AU4BmWKU9VdK\nrXhhvgZAEctUEZgBVBSRrIA/4IP5dGOHRGStUuqutY3qloymaZqDcFKJm+IjInmBRiTsYpPNgPnK\nbB+QRURyAfWALUqpO5aKZQtQP96/KQEb1DRN05KBDa8nMwkYAES9UD7K0iU2UUTSWsryAFdizBNs\nKYur3Kr/THfZ7n0HGTPpW0xRUbRsUp8uHVrbOxIA10Nv4jfiK27duYuTCK2aNaBD6+b2jhXNHvut\nYKH8TPouMPq+V/48TB47k9U//sSk2aPJky8XVy9f55Mug3hw/yEAQwM/p3rtKoSHRTCoz5ecPPoX\nr71elC/HDSJDRjdMpii+nTSHn1dvsXl+cNzX2zOOmm9o4Nf8umc/Wd2zsHrht/aOE+f7c+qs+fyy\ney9O4kRW98yMGtIPz+zZ7B030Ycwi0hXoGuMollKqVmWxxoDN5RSh0SkRox5BgMhQBpgFjAQGB5H\nDGWl3Kr/REvGZDIxcsI0ZkwYwdpFM/l56w7OXbhk71gAOBsM9O/9EesWz2LxrIksXbneYbLZa79d\nOHeJZjU/oFnND2hRqwPh4RFs+Wk7Xft8yN5d+6lb8V327tpP1z4fAlC9dhUKeHtRp0ILhvUbRcC4\nwQCEh0UwoJc/jd5uQ5c2vfEb2Y+MmTLYPL8jv97AsfM1b1iHb78eae8Y0eJ6f3b8oCWr5s8gaN40\nqlepyIy5i+0dFQAnpRI1KaVmKaV8YkyzYqy2CtBURC4CS4F3RGShUuq6pUvsCTAXqGCZPxjwirF8\nXuCalXLrf1Oi90YyOnbqb/LlzY1Xnly4uLjQoFZ1ftm1z96xAMjukZUSxQoD4OaWHu/8XoTevG3n\nVGaOsN8qVSvP5YtXuRYcQq0G1Vn143oAVv24ntoNawBQq351Vv34MwBHDh0nY+aMZM+RjYvnL3Pp\nvLl1fiP0Fndu3iGrh7vNMzvCfrPGkfP5lClF5kxJcoWQJBHX+zODm1v0POHhEYiD/ArSFt1lSqnB\nSqm8SqkCwPvAL0qp9pZxFkREgObAccsia4H/WY4yewu4r5S6DmwC6oqIu4i4A3UtZfH+TXESkSKW\nw9y+FpG8IrJBRB6LyBERKR/fypPKjZu3yOmZPfp+Dk8PbjjIB3lMV6+HcurMOUqXLGbvKIBj7LdG\nLerx00rz69Aje1Zuhpq3fzP0NtksFUaOXNkJuRYSvUzotVBy5PR8bj2ly5bEJY0Lly8E2zyzI+w3\naxw9n6N68f05eeYP1GrRgZ82b6dXF8e4Xo0tD2GOxSIROQYcAzyAZ03Qn4HzwFlgNtADQCl1BxgB\nHLBMwy1lVsVXCc4FfsPcJPodmANkAz4HvolrIRHpKiIHReTgwYMH48sQr9gu3uko3zyeCQsLp++Q\nkQzs0+25b0n2ZO/95uLiTK161diwdqvV+SSWUDGv2Jo9RzbGTR/OoD4Bz5Xbir33W3wcPZ8jiu39\n+Um3D9m2agGN6tZkcZBjXITPCZWoKaGUUjuUUo0tt99RSpVSSr2ulGqvlHpkKVdKqZ5KqUKWxw/G\nWH6OUqqwZZqbsL/JugyWvr6vgHCl1HKlVIRSaguQNq6FYvYP+vj4JCSHVTk8PQi5cTP6fuiNW2T3\nsP8g3TORRiOfDhlJo7o1qVOjir3jRLP3fqtWqwonjp7m9k3zl51bN++QPYd5+9lzZOP2LfPh9SHX\nbpAzd85/cufOwY1Qc263DG7MWjyZSaOnc+TQcZKDvfdbfBw9n6OJ7/3ZqG4Ntu7YY4dkL7PVIcz2\nFF8lE/NwtwdWHrOp14sX5XLwNYKvhRAZGcmGbTupWfWt5Nq8VUopvhg9Ce/8Xvi+/6694zzH3vut\n8bv1WL/qny7bXzbupEWbxgC0aNOYbRt2mss37aRFm4YAvPHm6zx68IibobdxcXFm+rzxrF72ExvX\nbku23Pbeb/Fx9HyOJK7356UrV6Nvb9+1j4L589ojXqoQ3yHMxUXkKOZuv0KW21jue9s0WQzOzgb8\n+nan22dDMZlMtGhcl8Le+ZNr81YdPnqCdRu3UaRQAVr69gTgk26+VKtcIZ4lbc+e+y2da1oqV6/A\nsH6jostmTZnH5O9G0+qDZlwPDqFP50EA7Niyh+q1q7B1/2rCwyMY3CcAgAbN6uBTqRxZsmbm3ffN\nldOg3gGcOv63TbM78usNHDtff/8xHDh8lHv3HlCreXt6dO5Ayyb17JYnrvfnyvWbuXg5GHEScuf0\n5Iv+ve2WMSax7S/+7SK+Sua1ZEmRANUqV3CID+4XlXvjdY7v2WDvGHGy136LCH9CxWK1nyu7d/c+\nvi17xDp/wMBxL5WtXbGBtSvss28d9fX2jKPmGx8wyN4RnhPX+9MR9x38Rw73fUVWKxmlVKwH34tI\nFaAd0NMWoTRN01KjVFfJxGQ5Q2c7oDVwAVhpq1CapmmpUarrLhORoph/vNMWuA38CIhSqmYyZNM0\nTUtVUmNL5jSwC2iilDoLICJ9bZ5K0zQtFUqJLZn4Ks6WmE+gtl1EZotILVLmZag1TdPsztY/xrQH\nq5WMUmqVUqoNUBzYAfQFcojIDBGpmwz5NE3TUg0nSdzkyBLUBaiUeqyUWmQ5HUFe4E/AsY5V1DRN\n+48TVKImRxbfwH864GOgMOaTqH1vOSHaTMukaZqmJZHUOPA/D4jEPPjfACiB+TrRmqZpWhITcexW\nSWLEV8mUUEqVAhCR74H9to+kaZqWOjmlwkom8tkNpZQxtlOya5qmaUkjJX7CirXrc4iICXj87C7g\nCoRZbiulVKb4NhAQEJDyqmZN0zQLf3//JKsbDuRpkajPy/JXVzls/RTfucsMSbERv56OcdW5FwVO\nW6CzJULgtAX4dW9n7xixCpyxmGXTf7Z3jFi17tHQofebfr29usAZi5N0falxTEbTNE1LJilxTCYl\nHjGnaZqmOQjdktE0TXMQKfHYKl3JaJqmOQg9JqNpmqbZTEock9GVjKZpmoPQ3WWapmmazejuMk3T\nNM1mdHeZpmmaZjPipCsZTdM0zUb0mIymaZpmM7olo2maptmMHvhPRtdDb+I34itu3bmLkwitmjWg\nQ+vmACxavoYlQeswGAxUq1yBfj07J3u+oYFf8+ue/WR1z8Lqhd8CMHXWfH7ZvRcncSKre2ZGDemH\nZ/ZsyZ7tRSaTiTad++CZ3YPp4wPsmuXBw0f4j53C2QuXQWDEoE8omC8v/fzHci0klNw5czBh+CAy\nZ8xgswwZM2Vg+NdDKFzcG6UUw/qOJCLsCV+MH0h6N1euXbnOgO7+PH5kPgF5lz6+tGzXBJMpitFD\nJrBnx+8AtP+oDa3aN0MQVixaw4JZS22WGSzP40d98fTIxvRx/gwcPp4Tp8/i7Gzg9deK4t+/Fy7O\nyf+Wju29cPrMeUaMn0pYeAS5c3ky1n8AGdzckj0bQN33OuGW3hUnJycMBgPLvptEP/+xXLwcDMDD\nR4/JmMGNoLlT7ZIvJj3wn4ycDQb69/6IEsUK8/hxGK0796Fy+bLcvnOP7bv3sXL+dNKkScPtu/fs\nkq95wzq0a9kUvxFfRZd1/KAlvbv+D4CFy9cwY+5i/Af0tku+mBYuX4N3gXw8ehxm7yiMmTKLKhXf\nZOJIPyIjIwmPeMLsBct468036NL+Pb5buJzvFy7ns+4dbZZh8MjP2L19L327DMbFxZl0run4btlU\nxgdM4eDew7Ro24ROPdszdexMChUtSMPmdWharS2eOT34bvk3NKr0Ht5FC9CqfTPer9+RyKdGZi6d\nxM4te7h84YrNci9cvhbv/F7Rz2OjOjUYM+xzAAYEjCdo3Wbeb9HQZtuPS2zvBf8xk/i8VxfKly3N\nyvWbmLsoKPq9YQ9zJgfiniVz9P0JAQOjb4//5ju7VYAvkhR4Nkmrf5KIZBeRErGUlxSR7LaLBdk9\nslKiWGEA3NzS453fi9Cbt/lx9U90bt+aNGnSAJDNPYstY8TJp0wpMmfK+FxZzBdqeHiEQwzihdy4\nya+/7adlk3r2jsKjx2EcOnKClo3rAuDi4kKmjBnYvvt3mtWvBUCz+rX4Zdc+m2Vwy+DGm5XKErRo\nLQCRkUYePnhEgcL5Obj3MAB7d/5OnUY1AahZvxo/r95C5NNIrl6+zpULwZQqVwLvIgU4cug4EeFP\nMJlMHPztMLUbVrdZ7pAbt/h174HofQdQrVJ5RAQRodRrRQm9ectm27cmtvfCxcvB+JQpBUCl8uXY\nsnO3PaLFSynFxu27aVi7mr2jAObussRMjiy+enMqEFtlkheYnPRxYnf1eiinzpyjdMliXLx8lUNH\njtP2o0/5sGd/jp36K7liJMjkmT9Qq0UHftq8nV5d7H99jrGTZ/JZj86IA3xFCr4WgnuWTAwNnESr\nTn34YswUwsIjuH33Htk9sgLmLxd3bNg69cqfm7u37zJq8jBWbJ1PwNd+uKZPx5nT56hZ3/xBU69J\nLXLm8QQgR87shFwNjV4+5PoNcuT05Ozp8/i8VZbM7plI55qWt2tXJmeeHDbLPXbKLD7r0Qlxevmb\nS6TRyLpN26lasZzNtv+qCnsXYPtu85eFzdt3ERJqnwoQQETo+tkXtO78CcvXbnzusUNHTpDNPQv5\nvfLYKd3zxEklanJk8X3ylFJK7XyxUCm1CSgd10Ii0lVEDorIwYMHD/6rgGFh4fQdMpKBfbqRwc0N\nk8nEg4ePWDxrIv16duHzYaOxdnXP5PZJtw/ZtmoBjerWZHHQOrtm2bHnd7K6Z6Fk8SJ2zfGM0WTi\n1N/naNO8ISvmTMHVNS3fL1qerBkMzgZeK1WMpfNW0qr2/wgPi6BLb1+GfTqSth1bsWzzPNJnSE/k\nUyNg/oB6kVKK82cu8v038/lu2VRmLpnMXyfOYDKabJJ5h2W8o6SlZf+ikROm82aZkrz5xus22X5i\njPDry5KgdbTu1JvHYeG4uNivZ37B9HEsnzOZGV8FsGTleg7+eTz6sZ+37nSYVgyYD2FOzOTI4qtk\nXBLzmFJqllLKRynl4+Pjk7hkmL+hfTpkJI3q1qROjSoA5PD0oHb1KuYughLFEBHu3ruf6G3YSqO6\nNdi6Y49dMxw+epIdu/dRt6Uv/f3HsP/QEQYGjLNbnpzZPciR3YPSJYsBULdGFU7+dY5s7lm4eesO\nADdv3SGrDbtAQ6/dIPTaDY79cQKAzet+4bVSxbhw9hJd2/ShdV1ffl61mSuXzIPCIddvPNdCyZnL\nkxuhNwFYuXgd79Xxxbf5x9y/94BL520zHnP42El27Pmduu91ov+X49j/x1EGDjePf0yfu5i79x4w\noFcXm2w7sbzzezF7UiDL5kylYe3qeOXJZbcsnh7mg2+yuWehVrVKHDv1NwBGo4mtv+6l/jsOVMmk\nwpbMGRF5aSRRRBoA520TyUwpxRejJ+Gd3wvf99+NLn/n7UrsP/QnYO73jTQanxvQs6dLV65G396+\nax8F8+e1Yxro270j21YvZHPQPMYHDKLCm28w1n+A3fJ4ZHMnp6cHFyxH9ew7dIRCBfJRo0pF1mzc\nBsCajduoWbWizTLcunmHkGs3KFAoHwBvve3Dub8vkNXDHTC3XLr17cSP81YBsH3TrzRsXgeXNC7k\nyZeLfN5eHPvjJED0Mrny5KB2wxr8vGqzTTL3/fhDtq2cx+blcxj/5QAqlCvN2C8+Z8W6TezZ/wfj\nvuyPk5P9u0NjenZATlRUFDPnLaV18+Q/IAEgLDyCx2Fh0bd/O3CYIt75Adh36E+88+Ulp6eHXbKl\nFvG1YfsC60WkNXDIUuYDVAIa2zLY4aMnWLdxG0UKFaClb08APunmy7uN6zI0cCLN23+Mi4szgUP7\nxdqlYWv9/cdw4PBR7t17QK3m7enRuQO79h7g4uVgxEnIndOTL/rb/8gyR+P36ccMHP4VkZFGvHLn\nZITfp6ioKPp9MYaVP20ml2d2vh4x2KYZAv2+Yuz04bikcSb40jWGfjKCpq0b0rZjKwC2/rydVUvM\nXZ3n/rrAxrVbWbtrKSajiZGDxhMVFQXApO/HkMU9M0ajkZGDx/Pg/kOb5n7RiAnTyJXDkw8+Nh9h\nVrtaZbp3bJusGSD290JYeDhLV64356pemRaN6sazFtu4ffcen/iNBMBkiqJhnepUrfgmABu2/koD\nB+oqg5T5Y0yJbzxDRNIC7YBnHb4ngMVKqYiEbCAgIED59bT/AHhsAqctQGd7dYHTFuDXvZ29Y8Qq\ncMZilk3/2d4xYtW6R0OH3m/69fbqAmcsxt/fP8m+5V4pXytRtYzXgW0OOzJjtSUjIt9grlDmJlMe\nTdO0VCsltmTiHZMBJojIRREZKyJlkiOUpmlaaiROiZscmdV4SqnJSqlKQHXgDjBXRE6JyBciUjRZ\nEmqapqUSqfHHmAAopS4ppcYqpcpiHp9pAZyyaTJN07RUJiW2ZBL0CykRcQHqA+8DtYCdgH3PtKhp\nmpbCpMQxmfgG/usAbTEfrvw7sBToqpR6nAzZNE3TUhVHb5UkRnx/kh+wFyiulGqilFqkKxhN0zQb\nEZW4Kb7ViqQTkf0ickRETohIgKW8oIj8LiJnRORHEUljKU9ruX/W8niBGOsabCn/S0TiPfNufJVM\nQyADMNxyPjKHvTSApmnaf50Nx2SeAO8opd4AygD1ReQtYCwwUSlVBLgLPLs4V2fgrlKqMDDRMh+W\ns/K/D5TEPIQyXUQM1jYcX7wfgHLAMcwVzoQE/TmapmnaK7NVJaPMHlnuulgmBbwDrLCUzwOaW243\ns9zH8ngtMZ9apRmwVCn1RCl1ATgLVLC27fhaJiWUUqUAROR7YH/8f46maZqWGIkdkxGRrkDXGEWz\nlFKzXpjHgPn0YIWBacA54J5SymiZJRh4ds2DPMAVAKWUUUTuA9ks5TEv+BRzmVjFV8lEPrth2VA8\ns2uapmmJlshKxlKhzIpnHhNQRkSyAKuA12KbzfJ/bB/2ykp5nKyeu0xETMCzgX4BXIEwy22llMpk\nbeVgPndZfPNomqb9VyXluctuN6qeqM/LbD/tfKUMIuKP+bN8IJDT0oioBHyplKonIpsst/daxuJD\nMF/AchCAUmq0ZT3R88W1LastGaWU1QGdhHLoE+/pbK9MZ0ucwGkLmDMlyN4xYtWpT0uH3m+OfILM\nJGWjQ5hFJDsQqZS6JyKuQG3Mg/nbgVaYf57iC6yxLLLWcn+v5fFflFJKRNYCi0XkayA3UIR4hlH0\n0WKapmkOwoa/k8kFzLOMyzgBy5RS60XkJLBUREYCh4HvLfN/DywQkbOYTyn2PoBS6oSILANOAkag\np6UbLk66ktE0TXMUNqpklFJHgbKxlJ8nlqPDLJdyeS+OdY0CRiV02ynw96Wapmmao9AtGU3TNAch\nTinvCF5dyWiapjmKFNi3pCsZTdM0B6FbMpqmaZrt6JaMpmmaZjO6JaNpmqbZiu4u0zRN02xHd5dp\nmqZpNqNbMpqmaZqt6O4yOzOZTLTp3AfP7B5MHx9g7zjRFixbTdDajSilaNW0Ph3atLB3JACePHmK\nb8/+PI2MxGQ0UadmVXp1se9JEIcGfs2ve/aT1T0Lqxd+C8DUWfP5ZfdenMSJrO6ZGTWkH57Zs9k1\n5+59Bxkz6VtMUVG0bFKfLh1a23yb3oUL8M1346Lv5yuQl69HTyfkeih9B3ancFFvmtZpx7E/TwLQ\nvFVDuvb6MHr+10oWpVHNNpw8/hdN321Az75dUEoRGnKTTz8ezN0792ySO7bntN+w0Vy8HAzAw0eP\nyJghA0Hzptlk+9Y8efIU394Defo0EpMpijo1qtCr8wcMGTWRg0eOk8EtPQCj/PpSvIh3sud7ia5k\n7Gvh8jV4F8jHo8dh9o4S7cz5iwSt3ciS7ybh4uzCx/2GUq1yBfJ7Wb2OT7JIk8aFOVPGkD69K5FG\nI//r/jlvv+XDG6/HdhmJ5NG8YR3atWyK34ivoss6ftCS3l3/B5if4xlzF+M/oLe9ImIymRg5YRqz\nJwWS09ODNl0+oWbVihQqmN+m2z1/9iINa5grMycnJ34/vpVNP23DNX06uvl+RuCEYc/Nv3rFz6xe\n8TMAxV4rwncLJ3Py+F8YDAb8AwdSu3Jz7t65x2D/vvh2acukcTNskju253TCiMHRt8dPnR39YZ7c\n0qRxYc6kwH/eAz0G8PZbbwLQr3tH6tasapdccUqBlcx/Zpgp5MZNfv1tPy2b1LN3lOecv3iF0iWL\n45ouHc7OBnzKlGLbr7/ZOxYAIkL69K4AGI1GjEYj9r7wnE+ZUmTOlPG5sgxubtG3w8MjsPe18Y6d\n+pt8eXPjlScXLi4uNKhVnV927Yt/wSRUpVpFLl+8wtXg65z9+wLnz160On/Tlg1Yu3IDYH7eRYh+\n7jNkdCM05IbNssb2nD6jlGLjL7/SsE4Nm23fmpffAyYk1utuOQbzc/fqkyOzWsmIiIeI+ItIHxHJ\nICIzROS4iKwRkcLJFRJg7OSZfNajM2LDc2EnRmHv/Bw6cpx79x8QHhHBrr0HCAm9ae9Y0UwmEy19\ne1KtcVsqlS9L6ZLF7R0pVpNn/kCtFh34afN2u3fp3bh5i5ye2aPv5/D04MbN28maoem79aMrjYRo\n0rwea4LM8xuNRoZ+PopNu4M4cGIbRYoV4seFq2wV1apDR46Tzd3dri17k8lEy469qda0PZXKl6F0\nyWIATJm9gBa+vRg7ZTZPn0bGs5Zk4iSJmxxYfJ/Yi4G0/HNhmvOYL2CzHvguroVEpKuIHBSRgwcP\nHvzXIXfs+Z2s7lkoWbzIv15XUitUIB+dPniPjz714+PPhlG0sDcGQ5Jc6y1JGAwGguZNY9uqBRw7\n+Tdnzl+0d6RYfdLtQ7atWkCjujVZHLTOrlliu1hscn5ZdHFxpnb9Gvy0ZnOC5i/zZinCwyP4+/RZ\nAJydnWnfqTUNa7SmfOZkIE0AABipSURBVMlanD75Nz37drZl5Dj9vGUHDetUt8u2nzEYDATNncq2\noB84dsr8Hvi0my/rFn3Lj7Mncv/hQ75ftMKuGaOlwkomh1LKD+gDZFBKjVdKnVZKzQayxLWQUmqW\nUspHKeXj4+Pzr0MePnqSHbv3UbelL/39x7D/0BEGBoyLf8Fk0rJJPZbP/YZ508fz//buO0yKas3j\n+PclmECQbECRzCogoqIMQRAk6gXUdVFRr2FBAa+SvIosAxfEgKBexYAIKgsihjViuAgiIAgjIkEU\nCYJImCEb0AvDu39UzdAzdBiaruqi+/08Tz9Uneqe+vWppk+fqlNVZcucHIjjMYWVObk0FzVuyLyF\nR9/oe6lzu1bM/Gx+UjNUqVyRrdmHeqPbsrdTqaJ/AxFatW3OimWr2J6zs0jPv7JbwV7POQ2cX+ob\nf3QOvL//9idccFGjxAeN4cCBXGbO+YIObVr6vu5wypxcmovOb8C8L5dQqWJ5RITjjitJ105tWb5q\ndbLjOYoVi+8RYLHS5QKoqgLbCy076EmiMPrdeQufvv2/fPLmy4wefh9NLjiPRzLv9Wv1Me3Y5Yza\n2bI1m0/nzKdj2+T+csuzc9du9v7yKwB//PknCxd/TfVqZyY51eE2/PRz/vTsuQupXq1qEtNA/Xp1\n2LhpM5s2b2X//v18+OkcWje/xLf1/+WqjkXeVSYidO7SrsDzt27JpnadGpSvUA6AFq0uYc3qdZ5k\njWZh1tfUqFa1wK5Hv+3ctafg/4GspVQ/qyo5250GXFWZNXchtWt4O6ijyFKwJxNrdFkN957OEjKN\nO1/d02THkH6DR7J7715KlCjBAwN6RzwI6recHbt4YORj5B48iB5U2l/WglbNLk5qpkGZD7P462Xs\n3r2XNl170Pu2G5m7YDE/btyEFBNOP7UyQwclb2QZQIkSxRnc70569R9Cbm4u3a5oRy2fvoROOPEE\nWrRqyuD+I/LL2ne+jOEP30/5CuWY9Oo4vl3xHTf9550AXJxxAVs2b+OnDYca6uytOTwx+jlef38S\n+/cf4OeftjCg7xDPMofbpldf2Z4PZ86hY9tWnq23KHJ27OSBUY+Tm3sQ1YO0b92CVs2acOvdg9m1\new+qSt1aNcgc2CepOVNZrEamS8j0Y4WWFZ73RZPGDWnSuGEyVh3RK88mpSpiqlurOm+85P+5CdGM\nHn7fYWVBGzEI0DKjCS0zDrsrref+2PcHjWoX3L308Qez+PiDWWGfv3B+Ft3a9zisfMpLrzPlpdc9\nyVhYuG0K8OCQAb6sP5q6tarzxsR/HlY+8clRSUgTW9qdjKmqc/wKYowxaS8FG5lYQ5hri8gkERkr\nIlVF5EMR+VVEvhGRoz+ib4wx5hApFt8jwGKlmwQsADYDXwITgYrAQCBY+2GMMeZYl4IH/mM1MqXd\n4ciPAftU9XVV/UNV/4Vz/owxxphEScFGJtaB/9BhynujLDPGGHOUJODnvMQjViNTT0SW4QxZrulO\n484H4JKlxhiTQgLeK4lHrEYmeZfrNcaYdBPwg/jxiDWEeUO4chEpDnQHwi43xhgThxTsycQawlxG\nRO4XkadFpJ047sK5UKb3d3Eyxph0koLXLou1u2wysAtnGPPtwCDgOKCLqi71OJsxxqSXFOzJxLx2\nmao2ABCRCTgXyTxLVX/xPJkxxqSbFDwmIxru5hl5C0WWqGrjSPNFMXz48MgrMMaYY1xmZmbCuh+/\nPXRzXN+Xpe5/ObBdoFg9mfNEJO/8GAFOdOcF5w4AZYqyksF9knunw0hGjZts2eJg2eIT+Gw9g3mY\nddT46YGut0RKu/NkVDU4t3g0xphUl4bHZIwxxvglBY/JpN47MsYYExjWkzHGmKCw3WXGGGM8k24H\n/o0xxvhIrCdjjDHGK9aTMcYY4xlrZIwxxnjGDvwbY4zxTAqeJ2ONjDHGBEUK7i5LvXdkjDHHKCkm\ncT1i/l2RiSKSLSIrQsqGicjPIrLUfXQKWXa/iKwRke9FpH1IeQe3bI2I3FeU93TMNDLzFmZxRffb\n6XjtrUyYPD3ZcfJt2ZbDLX3/zpXX96TLDb2YPP3tZEcqIKj1BpbtaCQ735BHnqJl15vp+te/5Zft\n2fsLtw/IpNMNd3L7gEz2/PJrgdcs/+4HGl52FZ989oXfcfMlu95ikmLxPWJ7CegQpvxxVW3kPmYA\niMg5OHc+Ptd9zTMiUty9I/I4oCNwDnCd+9yojolGJjc3l5FjxvHsmBG8O+V5Zsz8jLXrg3Hn5xLF\nizPorv/mvanjmTr+caa99X5gsgW53ixb/IKQr2uHy3ju0aEFyiZMfZNLGjdkxpRnuaRxQ16c+maB\nzI8//wrNLmrka85QQai3mDy6M6aqfg7sLGKKLsA0Vf1TVdcDa4Am7mONqq5T1X8D09znRn9LRVxp\nUi1ftZqzqp7OmWecRsmSJenY5lJmzV2Y7FgAVKpYnnPq1gKgVKmTqFHtTLbl7EhyKkeQ682yxS8I\n+S4871zKnly6QNns+Yvo0qE1AF06tGbWvC/zl0196wMub9mU8qeU9TVnqCDUW0xxNjIi0lNEskIe\nPYu4xr4isszdnVbOLTsD+CnkOZvcskjl0d9SEYMgIieJyIUiUqmor0mU7JztnFr50GqrVK5IdkC+\nyEP9vGUbq35YS8Nz6yY7ChDserNs8Qtqvh07d1OpQnkAKlUoz85dewDYlrODT+d9ybV/aR/t5Z4L\nar0VIBLXQ1XHq+qFIY/xRVjbs0BNoBGwBRiTlyLMczVKeVQRGxkR+YuI/CgiS9wDQiuBp4HlInJz\ntD8a2qpmZWXFyhBTuJt3Bu3qC7//vo9+D4zk73/rRelSpZIdBwh2vVm2+AU9X2GPPP0i/XreRPHi\nyb091TFRbx7tLgtHVbepaq6qHgRewNkdBk4P5cyQp1YFNkcpjyraEOYRQDugLDAbaKiq60SkMvAp\n8HKU8OOB8ZCY2y9XqVyRrdk5+fPbsrdTqWKFo/2zCbP/wAHueWAkndu15vJWzZIdJ1+Q682yxS+o\n+SqUP4WcHTupVKE8OTt2Ur6cs2ts5fdrGPSPxwDYtecX5n65hOLFi9GmxSW+5gtqvRXg43kyInKa\nqm5xZ7sBeSPP3gWmishY4HSgNrAIpydTW0SqAz/jDA64PtZ6or2jg6q6WlUXA+tVdR2AqmYDB+J4\nT3GrX68OGzdtZtPmrezfv58PP51D6+b+fkAjUVWGPvQENaqdyc3dr0p2nAKCXG+WLX5Bzdcqownv\nfDQbgHc+mk3rZs4P44+njeeT117gk9deoN2lTRlyTy/fGxgIbr0V4FFPRkReBRYAdUVkk4jcBjwq\nIstFZBnQGugHoKorgenAt8BHQB+3x3MA6At8DKwCprvPjSpaT6aYeyCoGHDQnc7rXPo6YKBEieIM\n7ncnvfoPITc3l25XtKNWjWp+Rojo62Uree+jT6ld82yuvrkPAHf3upmWGU1ivNJ7Qa43yxa/IOQb\n9I8xLF66gt179tLmmtvofUt3br/+KgYMH81bM2ZyWpWKjB12r6+ZYglCvSWLql4XpvjFKM9/EHgw\nTPkMYMaRrDtaI1MW+IpDDcuS0HUdyUoSoWVGk0B8cRfW+Lz6rJj/YbJjRBTUegPLdjSSnW/00AFh\ny18cOyLq6x68/24v4hRZsustphQ84z9iI6OqZ/uYwxhjTOBGIhy9aKPLeoRMNyu0rK+XoYwxJi35\nOLrML9HS9Q+ZfqrQsls9yGKMMektBRuZaMdkJMJ0uHljjDFHK80u9a8RpsPNG2OMOVoB75XEI1oj\nU88dPy1ATXcad76G58mMMSbdpFlPZjYwCufMTuu5GGOM19KsJ/MJ8BhwGvAa8KqqLvUllTHGpKMU\n7MlEfEeq+qSqNgUuxbkPwSQRWSUiQ0Wkjm8JjTEmXaTg6LKY6VR1g6o+oqrn41wMrRvOdWuMMcYk\nUjo2MiJSUkSuFJEpwIfAauBqz5MZY0y68e72y0kjGu4mC4CIXA5cB3TGuczzNOBtVf3tSFaQiEv9\nG2NMUGVmZibsvMF9M5+L6/vyxLZ3BPbcxWgH/gcDU4GBqlrUe0OH/0N9bjyal3tm1LjJli0Oli0+\nli0+o8ZN5r5rmic7RlgPvzEvsX8w4L2SeES7QGZrP4MYY0zaC/jxlXhE68kYY4zxUwr2ZFLvHRlj\njAkM68kYY0xQ2O4yY4wxXhEpnuwICWeNjDHGBIX1ZIwxxnjGGhljjDGeScHRZdbIGGNMUFhPxhhj\njGesJ2OMMcYzxWx0mTHGGK+kYE/mmHlH8xZmcUX32+l47a1MmDw92XEKsGzxCVq2IaPG0rJzd7r2\nuCO/7ONZc+lyQy8aNO/EilWrk5iuoKDVXZ5wdZgMubkHuXbAKPo++AwAqso/p7zDlX2G0eWu4Uz5\nYHZ++cMTptO5dyZX9xvJt2s3JjN2et5PJghyc3MZOWYcz44ZwbtTnmfGzM9Yu35DsmMBli1eQczW\ntdPlPDd2ZIGyWjWq8cSo/+GCRvWTlOpwQay7POHqMBmmfDCb6lVPzZ9/Z9ZCtm7fxTtPDeWdpzLp\n0OxCAOYtWcmGLdm8P24YQ++4gZHjpyUrsiMF7ycTMZ2IlPMzSDTLV63mrKqnc+YZp1GyZEk6trmU\nWXMXJjsWYNniFcRsFzZqQNkyJxcoq3n2WVSvVjVJicILYt3lCVeHftu6fReff7WCq9o2yy+b/vHn\n3HFtJ4q5v/ornOJknL1oGVe2uhgR4by61fnlt9/J2bknKbnBOeM/nkeQRWsCvxeRlSLygoj8VUTq\n+JaqkOyc7ZxauVL+fJXKFcnO2ZGsOAVYtvgEOVvQWd1F9+jEN+h/UzeKyaH7eP20dTsfzf+K7oMe\n5s4RT7NhczYA2Tt3c2rFQ7+nq1QoR/bO3b5nzpdOu8tUtTLQDZgPZABvicg2EXlHRO6N9kdFpKeI\nZIlIVlZW1lGHDHfzTgnIfeAsW3yCnC3orO4im5O1nPJlS3NOzbMKlP/7wAGOL1mSaaPv4+rLmzF0\n3GTAOSZTmCSzMlNwd1nU0WWquhpYDbwkIjWBTsDdQDvg0SivGw+Mh8TcfrlK5Ypszc7Jn9+WvZ1K\nFSsc7Z9NCMsWnyBnCzqru8iWfreWzxYvZ96Slfy5/wC//b6P+5+YRJUKp9C26fkAtLm4EUOfdhqZ\nKhXKsXX7rvzXb9uxi0rlyiYlOxD4Xkk8oh2TyRCRgSLypogsAh4EigM9AF+3Qv16ddi4aTObNm9l\n//79fPjpHFo3v8TPCBFZtvgEOVvQWd1FdnePrsycMIqPnh/Jo/1vpUmDujx0zy1c1uQ8Fi3/HoCs\nlT9Q7bTKALS6qAHvffYlqso336/n5JNOpFL5JDYyadaTmQcsAcYCb6vq7/5EOlyJEsUZ3O9OevUf\nQm5uLt2uaEetGtWSFacAyxafIGYblPkwi79exu7de2nTtQe9b7uRsmVK89Djz7Jz9x56D8qkXu0a\njH/8waTmDGLd5QlXh1df2T7Zsbj1qnbc//gkJr83i5NOOJ5hvXsA0OKC+sxdspLOvTM54fjjGNH3\nxuQGTbOTMU/HORaTAdwhIiVwGp0FwAJVXedDvnwtM5rQMqOJn6ssMssWn6BlGz38vrDlbS9tFrY8\nmYJWd3ki1WEyXFS/DhfVd8YrlSl1EuOG9DnsOSLCAz27+x0trURsZFR1K/CW+0BETgJuBYYD1XF2\nnRljjEmUgO/6ikfERkZEygJNOdSbOR9YA7yHM+LMGGNMIqXggf9ou8vWAAuBL4ARwCJV3edLKmOM\nSUOSTj0Z4AxV/bdvSYwxJt2lYE8m2jvKv06FiDzlQxZjjElvaTaEOfS01+ANrzHGmFSTZkOYj/pM\nfWOMMUcg4L2SeERrZOqJyDKcHk1Ndxp3XlW1oefpjDEmnaTgMZlojcxsYBTwM9arMcYYz3k1ukxE\nOgBP4pzfOEFVH/ZkRWFEa2Q+AR4DTgNeA15V1aW+pDLGmHTkQU9GnBvOjAMuBzYBi0XkXVX9NuEr\nCyPapf6fVNWmwKXATmCSiKwSkaHJvLeMMcakLG9GlzUB1qjqOve0lGlAF8/fi0vC3U8h4pNFzgcm\nAg1VtUjDIBJxqX9jjAmqzMzMhN2AZv/2dXF9X5asWCNiBhG5Buigqre78zcCF6tq3/hSHpmo95MB\nEJGSQAegO9AGmINz/bIiSeQGcPP0dO9XEziWLT6WLT6WLT5BzhatsYhGRHoCPUOKxoe8x3B/07cf\n/xF7MiJyOXAd0BlYhNPFeltVf/MrXIRcWap6YTIzRGLZ4mPZ4mPZ4hPkbF4QkabAMFVt787fD6Cq\nD/mx/mg9mcHAVGCgqu70I4wxxpiEWwzUFpHqOKOFuwPX+7XyaJf6b+1XCGOMMd5Q1QMi0hf4GGcI\n80RVXenX+mMekwmgQO5LdVm2+Fi2+Fi2+AQ5mydUdQYwIxnrPqLRZcYYY8yRSL1rGBhjjAkMa2SM\nMcZ4JnCNjIh0ExEVkXru/Nkisk9ElorItyLynLgX+BGROiIyQ0TWuFcjmC4iVTzIpCIyJmR+oIgM\nC5nvKSLfuY9FItI8ZNlnIvK9iHwjIotFpJEH+X4NUzZMRH526+07EXk2pN5eEpH1IcsyE50pJEeu\nu54VIvK6iJwUsqzAtnbLQrf3NyLyhYjU9Subu73aF3rePSLyjDvt12cuNNt7InKKWx6xfkSklYjs\ncZctE5GZIlI5wbki1c+MkFx5j5vc5T+KyHK3bLmIJPxs8yPMdbyIbBeRcu7zTnM/h6H/b3NEpEKi\nc6YlVQ3UA5gOzMUZ1w1wNrDCnS4BfA5cBZwA/ABcGfLa1kB9DzL9AawHKrrzA0PyXQF8FbKsMbAR\nONWd/wy40J2+BfiXB/l+DVM2DGf4OTg/JuYBrd35l4Br3OkTgHVAdY+2568h01OA/pG2deHt7c73\nAl72K5u7vkmFnrcQaOHzZy4028vAA7HqB2gFvB+y7CFgeIJzRaufFRFe82PI/4+6wAYP6uuIcgEf\nAJ3c6auBJcC9IRlXefGZS8dHoHoyIlIa5wZpt+GM5S5AVQ8AXwC1cMZ5L1DV90KWz1bVFR5EO4Az\nIqVfmGV/Bwap6nY3wxKcL4U+YZ67ADjDg3yxHIfzBbkrzLIT3H/9OMl2Ls62i7mtQ5QhfO5Ey8v2\nBnCFiBwPTs8BOB2nkfbzMxcq2ucmbP2IiAAnh1t2lCLVz6Yivt6r7XmkueYDGe50BjAWaBoy/4UH\nGdNSoBoZoCvwkaquBnaKSOPQhe6uljbAcqA+Tg/CL+OAG0SkbKHyc8PkyHLLC+sAvO1Btkj6ichS\nYAuwWgteRXu0u2wTME1Vs70MIiIlgI442w6ib+ua7m6NtTi9i7F+ZVPVHThXuOjgLu4OvKbOT1y/\nP3N5V9BtA7wbUhytflq423Uj0BbnWoMJE6l+cC5Tkpcr79Ei5KWzRWQFzmWphiQy0xHmGucu/4JD\njUwTnP+XZ7rzGTiNkEmAoDUy1+Fcvgb33+vc6Zruf5z5wAeq+qHfwVR1L/AK8LciPF0oeG2gKSKy\nCafX85QH8SJ5XFUbAZWBUiIS2mMY5C47FWgjIhlh/8LRO9Hddlk4X3wvuuWRtjXAWlVtpKo1gXvw\n7ryGSNle5VDvqrs777e8bDuA8sC/QpZFq5+57rIzgUnAox5ki1Q/ebnyHnNDXtNaVesDDYCn3Z5s\nMnLl7WFYBJwvIqWAkqr6K7BORGphPZmECkwj4x5kuwyYICI/AoOA/8L5ws77kJyvqsPcl6wELvA5\n5hM4u3dKhZR9GyZHY7c8zw1AdZzL9IzDZ6q6H/gIaBlm2a84x42aF16WIPtC/oPfpar/jrSt3V08\nhb0bLrdX2dzyt3Ea3sbAie4uUPD3M7fP/RFQDWd3Z7jdrxC9fryqu0j1E5OqrgW2AeckM5eq/g6s\nAW7FOR4DzjGcTjg/yr73IF9aCkwjA1wDvKKq1VT1bPeX2HqgaoTnTwUyRKRzXoGIdBCRBl4FVOca\nbtNxGpo8jwKP5I1EEWf02F+BZwq9dj/OboJLROQ/vMoYjvvlnQGsDbOsBHBxuGUeirStwzV0zX3O\nFtrwTqRgLyYZn7k9OL3ngeJcEb2waPXjSd1FqZ+Y3NFu1YENAcg1H6cnuMCdXwDcDSx0d4+aBAhS\nI3Md8H+Fyt7EuVDnYVR1H87IrrtE5AcR+Rbny93TYwvAGKBiSI53cT7UX4jId8ALQA9V3RIh8xic\n0WmJdJKIbAp59HfL847JrMAZmRfa8OUdk1mGc5zkrQRniibSts67aF/ePvRvcG4BfruP2fK8CpzH\noV16SfvMqerXwDcc2hUUrX5ahCy7ERjgUazD6ofDj8mE7lqe7X7eZgP3qeo2H3NFMh+owaFGZgnO\nj1rbVZZAdlkZY4wxnglST8YYY0yKsUbGGGOMZ6yRMcYY4xlrZIwxxnjGGhljjDGesUbGGGOMZ6yR\nMcYY45n/BzslTD4PMOeBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aca46a9390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "ax = sns.heatmap(conf_mtx_1, annot=True, fmt='d', cmap=sns.cm.rocket_r, \n",
    "                 xticklabels=x, yticklabels=x, robust=True, \n",
    "                 linewidths=0.1, linecolor='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9276723652075897,\n",
       " 0.9900207117303709,\n",
       " 0.976809471500061,\n",
       " 0.9756845258830905,\n",
       " 0.960650723025584,\n",
       " 0.9746096401900882,\n",
       " 0.6775244299674266,\n",
       " 0.8034934497816594]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = f1_score(labels_pred, labels_test, average=None)\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108081646607338"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
