{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN learning for arrhythmia classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import wfdb\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import biosppy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import save_model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import History\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, ELU, Dropout, Dense, Flatten\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all records names from [MIT-BIH Arrhythmia Database](https://physionet.org/content/mitdb/1.0.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100', '101', '102', '103', '104', '105', '106', '107', '108', '109']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = wfdb.get_record_list('mitdb')\n",
    "records[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need images of beats to learn CNN. So create and save images and labels for each beat of all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def signal_to_image(signal, folder_name, record_ind, signal_ind):\n",
    "    fig = plt.figure(frameon=False)\n",
    "    plt.plot(signal, linewidth=3.5) \n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    filename = folder_name + '/' + str(record_ind) + '_' + str(signal_ind) + '.png'\n",
    "    \n",
    "    fig.savefig(filename)\n",
    "    im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    im_gray = cv2.resize(im_gray, (128, 128))\n",
    "    cv2.imwrite(filename, im_gray)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return im_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_to_idx = {'nor': 1, 'lbb': 2, 'rbb': 5, 'apc': 0, 'pvc': 4, 'pab': 3, 'veb': 6, 'vfw': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'apc',\n",
       " 1: 'nor',\n",
       " 2: 'lbb',\n",
       " 3: 'pab',\n",
       " 4: 'pvc',\n",
       " 5: 'rbb',\n",
       " 6: 'veb',\n",
       " 7: 'vfw'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_class = dict(zip(class_to_idx.values(), class_to_idx.keys()))\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol_to_label = {'N':'nor', 'L':'lbb', 'R':'rbb', 'A':'apc', \n",
    "                   'V':'pvc', '/':'pab', 'E':'veb', '!':'vfw'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signal_ind = 0\n",
    "for record_ind, record in enumerate(records):\n",
    "    signals = wfdb.rdsamp(record, channels=[0], pb_dir='mitdb')[0]\n",
    "    ann = wfdb.rdann(record, 'atr', pb_dir='mitdb') \n",
    "    symbols = ann.symbol\n",
    "    beats = list(ann.sample)\n",
    "\n",
    "    for i in range(len(beats)):\n",
    "        if symbols[i] in list(symbol_to_label.keys()):\n",
    "            left_ind = 0 if i == 0 else beats[i - 1] + 20\n",
    "            right_ind = len(signals) if i == len(beats) - 1 else beats[i + 1] - 20\n",
    "            signal = signals[left_ind: right_ind]\n",
    "\n",
    "            signal_to_image(signal, 'signal_images', record_ind, signal_ind)\n",
    "    \n",
    "            with open('labels.txt', 'a') as f:\n",
    "                f.write(str(record_ind) + '_' + str(signal_ind) + ' ' + str(class_to_idx[symbol_to_label[symbols[i]]]))\n",
    "                f.write('\\n')\n",
    "                \n",
    "            signal_ind += 1\n",
    "\n",
    "    print(record_ind, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get images paths and get images IDs from the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = glob.glob('./signal_images/*.png')\n",
    "\n",
    "cropped_paths = {}\n",
    "beg = all_paths[0].find('\\\\') + 1\n",
    "for path in all_paths:\n",
    "    end = path.rfind('.')\n",
    "    \n",
    "    number = path[beg:end]\n",
    "    record_n = int(number[:number.find('_')])\n",
    "    sig_n = int(number[number.find('_') + 1:])\n",
    "    \n",
    "    if cropped_paths.get(record_n) is None:\n",
    "        cropped_paths[record_n] = 0\n",
    "    cropped_paths[record_n] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images labels from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107668"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_labels = {}\n",
    "with open('labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        n, l = line.split()\n",
    "        id_labels[n] = int(l)\n",
    "\n",
    "len(id_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha dataset is imbalanced, so we'll need to artificially augment smaller classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([ 2546, 75052,  8075,  7028,  7130,  7259,   106,   472],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(list(id_labels.values()), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of labels from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107668"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(list(id_labels.values()))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(np.unique(labels))\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107668 [23423 48798  7516 ... 17730 28030 15725]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(labels))\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(len(indices), indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method augments smaller classes ten times cropping and shifting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cropping_images(image):\n",
    "    #Left Top Crop\n",
    "    left_top = cv2.resize(image[:96, :96], (128, 128))\n",
    "\n",
    "    #Center Top Crop\n",
    "    center_top = cv2.resize(image[:96, 16:112], (128, 128))\n",
    "\n",
    "    #Right Top Crop\n",
    "    right_top = cv2.resize(image[:96, 32:], (128, 128))\n",
    "\n",
    "    #Left Center Crop\n",
    "    left_center = cv2.resize(image[16:112, :96], (128, 128))\n",
    "\n",
    "    #Center Center Crop\n",
    "    center_center = cv2.resize(image[16:112, 16:112], (128, 128))\n",
    "\n",
    "    #Right Center Crop    \n",
    "    right_center = cv2.resize(image[16:112, 32:], (128, 128))\n",
    "\n",
    "    #Left Bottom Crop\n",
    "    left_bottom = cv2.resize(image[32:, :96], (128, 128))\n",
    "\n",
    "    #Center Bottom Crop\n",
    "    center_bottom = cv2.resize(image[32:, 16:112], (128, 128))\n",
    "\n",
    "    #Right Bottom Crop    \n",
    "    right_bottom = cv2.resize(image[32:, 32:], (128, 128))\n",
    "\n",
    "    return np.array([left_top, center_top, right_top,\n",
    "            left_center, center_center, right_center,\n",
    "            left_bottom, center_bottom, right_bottom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use generators to train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator(ind, augment=False):\n",
    "    image = cv2.imread(all_paths[ind], cv2.IMREAD_GRAYSCALE)\n",
    "    number_path = all_paths[ind][all_paths[ind].find('\\\\') + 1 : all_paths[ind].rfind('.')]\n",
    "    label = id_labels[number_path]\n",
    "    \n",
    "    if augment and label != class_to_idx['nor']:\n",
    "        cropped_images = get_cropping_images(image)\n",
    "        images = np.vstack((np.expand_dims(image, axis=0), cropped_images)) \n",
    "        yield images, [label] * len(images)\n",
    "    else:\n",
    "        yield np.expand_dims(image, 0), [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, augment=False, debug=False):\n",
    "    global batch_i\n",
    "    \n",
    "    generators = np.array([get_generator(ind, augment) for ind in range(len(all_paths))])\n",
    "    while True:\n",
    "        batch_indices = indices[(batch_i - 1) * batch_size : batch_i * batch_size]\n",
    "        batch_i += 1\n",
    "        yield [gen.__next__() for gen in generators[batch_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size, augment=False):\n",
    "    for batch in raw_batch_generator(batch_size, augment):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(e[0])\n",
    "            batch_labels.extend(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0) if not augment else np.vstack(batch_images)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size, augment=False):      \n",
    "    for batch in images_and_labels_generator(batch_size, augment):\n",
    "        batch_images = batch[0]\n",
    "        batch_images = np.expand_dims(batch_images, -1)\n",
    "        batch_labels = keras.utils.to_categorical(batch[1], NUM_CLASSES)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 128, 128, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_i = 1\n",
    "train_iterator(32, augment=True).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for saving model after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "        self.f1s = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):     \n",
    "        model_filename = self.file_name.format(epoch % 3)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom F1 score mectric for measuring training quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    f1_val = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "            \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 126, 126, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 64)      36928     \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60, 60, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 58, 58, 128)       147584    \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 58, 58, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 27, 256)       295168    \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "elu_6 (ELU)                  (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              75499520  \n",
      "_________________________________________________________________\n",
      "elu_7 (ELU)                  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 16392     \n",
      "=================================================================\n",
      "Total params: 76,671,944\n",
      "Trainable params: 76,666,056\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3),strides = (1,1), input_shape = (128, 128, 1), kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "\n",
    "model.add(Conv2D(256, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',  # gradient clipping just in case\n",
    "  metrics=[keras.metrics.categorical_accuracy, f1] \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "STEPS_PER_EPOCH = 50\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count class weights to cope with imbalanced dataset during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401212"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_for_weights = labels\n",
    "for ind in [0, 2, 3, 4, 5, 6, 7]:\n",
    "    new_labels = np.full(sum(labels == ind) * 9, ind)\n",
    "    labels_for_weights = np.append(labels_for_weights, new_labels)\n",
    "len(labels_for_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9698154 ,  0.66822337,  0.62107121,  0.71359562,  0.7033871 ,\n",
       "        0.69088717, 47.31273585, 10.6253178 ])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(labels_for_weights), labels_for_weights)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 2505s 50s/step - loss: 3.0487 - categorical_accuracy: 0.5202 - f1: 0.5125\n",
      "Model saved in model_v3_0\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 2041s 41s/step - loss: 1.9249 - categorical_accuracy: 0.6332 - f1: 0.6229\n",
      "Model saved in model_v3_1\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 2500s 50s/step - loss: 1.2353 - categorical_accuracy: 0.6995 - f1: 0.6892\n",
      "Model saved in model_v3_2\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 2375s 47s/step - loss: 0.9178 - categorical_accuracy: 0.7479 - f1: 0.7446\n",
      "Model saved in model_v3_0\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 2172s 43s/step - loss: 0.7880 - categorical_accuracy: 0.7802 - f1: 0.7732\n",
      "Model saved in model_v3_1\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 2357s 47s/step - loss: 0.8071 - categorical_accuracy: 0.7569 - f1: 0.7560\n",
      "Model saved in model_v3_2\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 2560s 51s/step - loss: 0.7458 - categorical_accuracy: 0.7949 - f1: 0.7909\n",
      "Model saved in model_v3_0\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 2284s 46s/step - loss: 0.6898 - categorical_accuracy: 0.7991 - f1: 0.7958\n",
      "Model saved in model_v3_1\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 2517s 50s/step - loss: 0.6062 - categorical_accuracy: 0.8209 - f1: 0.8173\n",
      "Model saved in model_v3_2\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 2338s 47s/step - loss: 0.5817 - categorical_accuracy: 0.8259 - f1: 0.8238\n",
      "Model saved in model_v3_0\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 2282s 46s/step - loss: 0.5255 - categorical_accuracy: 0.8509 - f1: 0.8491\n",
      "Model saved in model_v3_1\n",
      "Epoch 12/100\n",
      "10/50 [=====>........................] - ETA: 32:52 - loss: 0.5282 - categorical_accuracy: 0.8316 - f1: 0.8376"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-d4cb3aa6c45c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_i = 1\n",
    "hist = History()\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback('model_v3' + '_{}'), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "50/50 [==============================] - 2482s 50s/step - loss: 0.6241 - categorical_accuracy: 0.8194 - f1: 0.8225\n",
      "Model saved in model_v3_2\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 2492s 50s/step - loss: 0.4698 - categorical_accuracy: 0.8559 - f1: 0.8583\n",
      "Model saved in model_v3_0\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 2659s 53s/step - loss: 0.4530 - categorical_accuracy: 0.8655 - f1: 0.8646\n",
      "Model saved in model_v3_1\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 2387s 48s/step - loss: 0.4535 - categorical_accuracy: 0.8666 - f1: 0.8678\n",
      "Model saved in model_v3_2\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 2674s 53s/step - loss: 0.4381 - categorical_accuracy: 0.8732 - f1: 0.8715\n",
      "Model saved in model_v3_0\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 2327s 47s/step - loss: 0.4403 - categorical_accuracy: 0.8645 - f1: 0.8660\n",
      "Model saved in model_v3_1\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 2419s 48s/step - loss: 0.3783 - categorical_accuracy: 0.8785 - f1: 0.8808\n",
      "Model saved in model_v3_2\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 2896s 58s/step - loss: 0.5502 - categorical_accuracy: 0.8378 - f1: 0.8369\n",
      "Model saved in model_v3_0\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 2908s 58s/step - loss: 0.2944 - categorical_accuracy: 0.9188 - f1: 0.9180\n",
      "Model saved in model_v3_1\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 3319s 66s/step - loss: 0.3241 - categorical_accuracy: 0.9010 - f1: 0.9006\n",
      "Model saved in model_v3_2\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 3124s 62s/step - loss: 0.4386 - categorical_accuracy: 0.8797 - f1: 0.8784\n",
      "Model saved in model_v3_0\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 2792s 56s/step - loss: 0.3478 - categorical_accuracy: 0.9088 - f1: 0.9066\n",
      "Model saved in model_v3_1\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 3177s 64s/step - loss: 0.2213 - categorical_accuracy: 0.9320 - f1: 0.9341\n",
      "Model saved in model_v3_2\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 2763s 55s/step - loss: 0.3260 - categorical_accuracy: 0.9003 - f1: 0.9004\n",
      "Model saved in model_v3_0\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 2837s 57s/step - loss: 0.3083 - categorical_accuracy: 0.9052 - f1: 0.9044\n",
      "Model saved in model_v3_1\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 2483s 50s/step - loss: 0.3126 - categorical_accuracy: 0.9154 - f1: 0.9155\n",
      "Model saved in model_v3_2\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 3321s 66s/step - loss: 0.2387 - categorical_accuracy: 0.9284 - f1: 0.9273\n",
      "Model saved in model_v3_0\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 3167s 63s/step - loss: 0.2359 - categorical_accuracy: 0.9332 - f1: 0.9323\n",
      "Model saved in model_v3_1\n",
      "Epoch 30/100\n",
      " 2/50 [>.............................] - ETA: 32:21 - loss: 0.2512 - categorical_accuracy: 0.9135 - f1: 0.9059"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ac72939b767d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_i = 551\n",
    "hist = History()\n",
    "model = load_model('model_v3_1', custom_objects={'f1':f1})\n",
    "file_name = 'model_v3' + '_{}'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, augment=True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(file_name), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "50/50 [==============================] - 3154s 63s/step - loss: 0.2899 - categorical_accuracy: 0.9081 - f1: 0.9065\n",
      "Model saved in model_v3_2\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 3279s 66s/step - loss: 0.2752 - categorical_accuracy: 0.9281 - f1: 0.9301\n",
      "Model saved in model_v3_0\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 3090s 62s/step - loss: 0.3463 - categorical_accuracy: 0.9038 - f1: 0.9022\n",
      "Model saved in model_v3_1\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 3402s 68s/step - loss: 0.3083 - categorical_accuracy: 0.9113 - f1: 0.9131\n",
      "Model saved in model_v3_2\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 3074s 61s/step - loss: 0.3095 - categorical_accuracy: 0.9085 - f1: 0.9083\n",
      "Model saved in model_v3_0\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 3171s 63s/step - loss: 0.2443 - categorical_accuracy: 0.9258 - f1: 0.9300\n",
      "Model saved in model_v3_1\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 3238s 65s/step - loss: 0.3502 - categorical_accuracy: 0.8957 - f1: 0.8996\n",
      "Model saved in model_v3_2\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 3293s 66s/step - loss: 0.2354 - categorical_accuracy: 0.9267 - f1: 0.9270\n",
      "Model saved in model_v3_0\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 3438s 69s/step - loss: 0.2180 - categorical_accuracy: 0.9329 - f1: 0.9312\n",
      "Model saved in model_v3_1\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 3272s 65s/step - loss: 0.3235 - categorical_accuracy: 0.9034 - f1: 0.9036\n",
      "Model saved in model_v3_2\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 3277s 66s/step - loss: 0.2446 - categorical_accuracy: 0.9199 - f1: 0.9232\n",
      "Model saved in model_v3_0\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 3230s 65s/step - loss: 0.2239 - categorical_accuracy: 0.9383 - f1: 0.9383\n",
      "Model saved in model_v3_1\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 3369s 67s/step - loss: 0.2286 - categorical_accuracy: 0.9304 - f1: 0.9300\n",
      "Model saved in model_v3_2\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 3346s 67s/step - loss: 0.2715 - categorical_accuracy: 0.9177 - f1: 0.9169\n",
      "Model saved in model_v3_0\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 2871s 57s/step - loss: 0.1845 - categorical_accuracy: 0.9449 - f1: 0.9437\n",
      "Model saved in model_v3_1\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 3506s 70s/step - loss: 0.3183 - categorical_accuracy: 0.9161 - f1: 0.9163\n",
      "Model saved in model_v3_2\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 2961s 59s/step - loss: 0.2834 - categorical_accuracy: 0.9200 - f1: 0.9211\n",
      "Model saved in model_v3_0\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 3047s 61s/step - loss: 0.3140 - categorical_accuracy: 0.9045 - f1: 0.9061\n",
      "Model saved in model_v3_1\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 2814s 56s/step - loss: 0.2160 - categorical_accuracy: 0.9391 - f1: 0.9399\n",
      "Model saved in model_v3_2\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 2991s 60s/step - loss: 0.2692 - categorical_accuracy: 0.9309 - f1: 0.9302\n",
      "Model saved in model_v3_0\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 3267s 65s/step - loss: 0.2980 - categorical_accuracy: 0.9046 - f1: 0.9049\n",
      "Model saved in model_v3_1\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 3074s 61s/step - loss: 0.1867 - categorical_accuracy: 0.9447 - f1: 0.9451\n",
      "Model saved in model_v3_2\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 2813s 56s/step - loss: 0.2140 - categorical_accuracy: 0.9400 - f1: 0.9408\n",
      "Model saved in model_v3_0\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 3886s 78s/step - loss: 0.2259 - categorical_accuracy: 0.9357 - f1: 0.9369\n",
      "Model saved in model_v3_1\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 3595s 72s/step - loss: 0.3039 - categorical_accuracy: 0.9077 - f1: 0.9078\n",
      "Model saved in model_v3_2\n",
      "Epoch 55/100\n",
      "25/50 [==============>...............] - ETA: 30:31 - loss: 0.2953 - categorical_accuracy: 0.9167 - f1: 0.9147"
     ]
    }
   ],
   "source": [
    "batch_i = 1451\n",
    "hist = History()\n",
    "model = load_model('model_v3_1', custom_objects={'f1':f1})\n",
    "file_name = 'model_v3' + '_{}'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, augment=True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(file_name), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=29\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 3791s 76s/step - loss: 0.2322 - categorical_accuracy: 0.9320 - f1: 0.9318\n",
      "Model saved in model_v3_0\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 3529s 71s/step - loss: 0.2852 - categorical_accuracy: 0.9124 - f1: 0.9132\n",
      "Model saved in model_v3_1\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 3157s 63s/step - loss: 0.3131 - categorical_accuracy: 0.9097 - f1: 0.9100\n",
      "Model saved in model_v3_2\n",
      "Epoch 58/100\n",
      "26/50 [==============>...............] - ETA: 30:51 - loss: 0.2634 - categorical_accuracy: 0.9243 - f1: 0.9259"
     ]
    }
   ],
   "source": [
    "batch_i = 2701\n",
    "hist = History()\n",
    "model = load_model('model_v3_2', custom_objects={'f1':f1})\n",
    "file_name = 'model_v3' + '_{}'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, augment=True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(file_name), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=54\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 2648s 53s/step - loss: 0.2275 - categorical_accuracy: 0.9399 - f1: 0.9391\n",
      "Model saved in model_v3_0\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 2324s 46s/step - loss: 0.2314 - categorical_accuracy: 0.9345 - f1: 0.9355\n",
      "Model saved in model_v3_1\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 2364s 47s/step - loss: 0.2116 - categorical_accuracy: 0.9346 - f1: 0.9364\n",
      "Model saved in model_v3_2\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 2640s 53s/step - loss: 0.2285 - categorical_accuracy: 0.9344 - f1: 0.9326\n",
      "Model saved in model_v3_0\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 2526s 51s/step - loss: 0.2520 - categorical_accuracy: 0.9331 - f1: 0.9335\n",
      "Model saved in model_v3_1\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 2299s 46s/step - loss: 0.1513 - categorical_accuracy: 0.9496 - f1: 0.9479\n",
      "Model saved in model_v3_2\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 2471s 49s/step - loss: 0.1795 - categorical_accuracy: 0.9416 - f1: 0.9429\n",
      "Model saved in model_v3_0\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 2584s 52s/step - loss: 0.2398 - categorical_accuracy: 0.9339 - f1: 0.9333\n",
      "Model saved in model_v3_1\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 2414s 48s/step - loss: 0.2216 - categorical_accuracy: 0.9271 - f1: 0.9281\n",
      "Model saved in model_v3_2\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 2389s 48s/step - loss: 0.2565 - categorical_accuracy: 0.9299 - f1: 0.9304\n",
      "Model saved in model_v3_0\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 2269s 45s/step - loss: 0.2201 - categorical_accuracy: 0.9380 - f1: 0.9388\n",
      "Model saved in model_v3_1\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 2782s 56s/step - loss: 0.2799 - categorical_accuracy: 0.9247 - f1: 0.9238\n",
      "Model saved in model_v3_2\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 2557s 51s/step - loss: 0.2781 - categorical_accuracy: 0.9213 - f1: 0.9232\n",
      "Model saved in model_v3_0\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 2737s 55s/step - loss: 0.1585 - categorical_accuracy: 0.9542 - f1: 0.9554\n",
      "Model saved in model_v3_1\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 2583s 52s/step - loss: 0.1893 - categorical_accuracy: 0.9441 - f1: 0.9452\n",
      "Model saved in model_v3_2\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 2917s 58s/step - loss: 0.2726 - categorical_accuracy: 0.9241 - f1: 0.9238\n",
      "Model saved in model_v3_0\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 2852s 57s/step - loss: 0.1577 - categorical_accuracy: 0.9555 - f1: 0.9557\n",
      "Model saved in model_v3_1\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 2518s 50s/step - loss: 0.1901 - categorical_accuracy: 0.9487 - f1: 0.9490\n",
      "Model saved in model_v3_2\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 2538s 51s/step - loss: 0.2334 - categorical_accuracy: 0.9399 - f1: 0.9409\n",
      "Model saved in model_v3_0\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 3058s 61s/step - loss: 0.2740 - categorical_accuracy: 0.9362 - f1: 0.9363\n",
      "Model saved in model_v3_1\n",
      "Epoch 78/100\n",
      "19/50 [==========>...................] - ETA: 31:43 - loss: 0.1334 - categorical_accuracy: 0.9610 - f1: 0.9636"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-eafa3a89f6a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m57\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_i = 2851\n",
    "hist = History()\n",
    "model = load_model('model_v3_2', custom_objects={'f1':f1})\n",
    "file_name = 'model_v3' + '_{}'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, augment=True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(file_name), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=57\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 3305s 66s/step - loss: 0.1079 - categorical_accuracy: 0.9687 - f1: 0.9693\n",
      "Model saved in model_v3_2\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 3022s 60s/step - loss: 0.1562 - categorical_accuracy: 0.9504 - f1: 0.9513\n",
      "Model saved in model_v3_0\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 2957s 59s/step - loss: 0.1439 - categorical_accuracy: 0.9568 - f1: 0.9573\n",
      "Model saved in model_v3_1\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 3034s 61s/step - loss: 0.1764 - categorical_accuracy: 0.9490 - f1: 0.9480\n",
      "Model saved in model_v3_2\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 3066s 61s/step - loss: 0.2322 - categorical_accuracy: 0.9392 - f1: 0.9419\n",
      "Model saved in model_v3_0\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 2717s 54s/step - loss: 0.1440 - categorical_accuracy: 0.9545 - f1: 0.9548\n",
      "Model saved in model_v3_1\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 2648s 53s/step - loss: 0.1899 - categorical_accuracy: 0.9500 - f1: 0.9516\n",
      "Model saved in model_v3_2\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 3562s 71s/step - loss: 0.1433 - categorical_accuracy: 0.9601 - f1: 0.9599\n",
      "Model saved in model_v3_0\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 3606s 72s/step - loss: 0.1412 - categorical_accuracy: 0.9551 - f1: 0.9572\n",
      "Model saved in model_v3_1\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 3528s 71s/step - loss: 0.2531 - categorical_accuracy: 0.9268 - f1: 0.9257\n",
      "Model saved in model_v3_2\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 3721s 74s/step - loss: 0.1711 - categorical_accuracy: 0.9439 - f1: 0.9458\n",
      "Model saved in model_v3_0\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 4019s 80s/step - loss: 0.1788 - categorical_accuracy: 0.9456 - f1: 0.9469\n",
      "Model saved in model_v3_1\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 3601s 72s/step - loss: 0.1558 - categorical_accuracy: 0.9502 - f1: 0.9509\n",
      "Model saved in model_v3_2\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 3836s 77s/step - loss: 0.1577 - categorical_accuracy: 0.9533 - f1: 0.9547\n",
      "Model saved in model_v3_0\n",
      "Epoch 92/100\n",
      " 6/50 [==>...........................] - ETA: 28:01 - loss: 0.5106 - categorical_accuracy: 0.8838 - f1: 0.8861"
     ]
    }
   ],
   "source": [
    "batch_i = 3851\n",
    "hist = History()\n",
    "model = load_model('model_v3_1', custom_objects={'f1':f1})\n",
    "file_name = 'model_v3' + '_{}'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE, augment=True), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(file_name), hist],\n",
    "    verbose=1,  \n",
    "    class_weight=class_weights,\n",
    "    initial_epoch=77\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each training stage quality metrics are saved in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('f1_scores.txt', 'a') as fout:\n",
    "    for val in hist.history['f1']:\n",
    "        fout.write(str(val) + '\\n')\n",
    "        \n",
    "with open('cat_accuracies.txt', 'a') as fout:\n",
    "    for val in hist.history['categorical_accuracy']:\n",
    "        fout.write(str(val) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
